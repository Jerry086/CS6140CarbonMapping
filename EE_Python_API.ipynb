{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jerry086/CS6140CarbonMapping/blob/main/EE_Python_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUpzfef3quYi"
      },
      "source": [
        "# Forest Carbon Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hK3sO_XwcR"
      },
      "source": [
        "## Authentication"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EcsqT7R8JNP",
        "outputId": "0598c520-d9a5-4937-d593-3cbec0e3d995"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDunjJcBZGFB"
      },
      "source": [
        "Authenticate and authorize access to Earth Engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xSjJTL_-tPkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297a894a-bee1-4a51-b603-cba53585475b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticating using Notebook auth...\n",
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=AvG0GkJlDB5ZiPA45Qu8dZhWSUgrGksrLgcyEnWl9H4&tc=arYQmN8K5Y2SmAEzJbyWWY1gFYO-dIF5IPsoSt1OgIk&cc=0ir6thDYuZS4LzE34Bog-lhtFfyrN4BA0nygMuswgns\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AZEOvhU1APTW_2k3UQOOEq5Sz1mndpJliN_Zw6dL2ws_W1hvhEPglxgt8nA\n",
            "\n",
            "Successfully saved authorization token.\n",
            "✓ Successfully initialized!\n"
          ]
        }
      ],
      "source": [
        "COLAB_AUTH_FLOW_CLOUD_PROJECT_FOR_API_CALLS = None\n",
        "\n",
        "import ee\n",
        "import google\n",
        "import os\n",
        "\n",
        "if COLAB_AUTH_FLOW_CLOUD_PROJECT_FOR_API_CALLS is None:\n",
        "  print(\"Authenticating using Notebook auth...\")\n",
        "  if os.path.exists(ee.oauth.get_credentials_path()) is False:\n",
        "    ee.Authenticate()\n",
        "  else:\n",
        "    print('\\N{check mark} '\n",
        "          'Previously created authentication credentials were found.')\n",
        "  ee.Initialize()\n",
        "else:\n",
        "  print('Authenticating using Colab auth...')\n",
        "  # Authenticate to populate Application Default Credentials in the Colab VM.\n",
        "  google.colab.auth.authenticate_user()\n",
        "  # Create credentials needed for accessing Earth Engine.\n",
        "  credentials, auth_project_id = google.auth.default()\n",
        "  # Initialize Earth Engine.\n",
        "  ee.Initialize(credentials, project=COLAB_AUTH_FLOW_CLOUD_PROJECT_FOR_API_CALLS)\n",
        "print('\\N{check mark} Successfully initialized!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFMJrbt8rZ9z"
      },
      "source": [
        "## Install & import Python packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoUgp_unsCfZ"
      },
      "source": [
        "Import other Python packages used throughout this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LVrJX9WDr_F-"
      },
      "outputs": [],
      "source": [
        "import altair as alt\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Folium setup.\n",
        "import folium\n",
        "print(folium.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYZur_13fU6N",
        "outputId": "a64760b7-7dee-47ed-ae4e-52792e23336a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow setup.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLPIT3XaqhkY",
        "outputId": "296d6352-bbc0-4d8a-df93-815016093091"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set global variables"
      ],
      "metadata": {
        "id": "qEqG89idJjVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify names locations for outputs in Google Drive.\n",
        "FOLDER = 'carbon_mapping'\n",
        "TRAINING_BASE = 'training_patches'\n",
        "EVAL_BASE = 'eval_patches'\n",
        "\n",
        "# Specify inputs (MODIS bands) to the model and the response variable.\n",
        "BANDS = ['NDVI', 'EVI']\n",
        "RESPONSE = 'annualNPP'\n",
        "FEATURES = BANDS + [RESPONSE]\n",
        "\n",
        "# Specify the size and shape of patches expected by the model.\n",
        "KERNEL_SIZE = 256\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "COLUMNS = [\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "\n",
        "# Sizes of the training and evaluation datasets.\n",
        "TRAIN_SIZE = 16000\n",
        "EVAL_SIZE = 8000\n",
        "\n",
        "# Specify model training parameters.\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "BUFFER_SIZE = 2000\n",
        "OPTIMIZER = 'SGD'\n",
        "LOSS = 'MeanSquaredError'\n",
        "METRICS = ['RootMeanSquaredError']"
      ],
      "metadata": {
        "id": "u-lC2KAKJk6h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afVIId1ysLYe"
      },
      "source": [
        "# Visualizing Images and Image Bands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kese6umry9Rp"
      },
      "outputs": [],
      "source": [
        "# Initialize Earth Engine\n",
        "ee.Initialize()\n",
        "\n",
        "# Load the MODIS Vegetation Indices (MOD13Q1) collection\n",
        "modis_collection = ee.ImageCollection('MODIS/061/MOD13Q1')\n",
        "\n",
        "# Define the region of interest (ROI)\n",
        "north_america_polygon = ee.Geometry.Polygon([\n",
        "    [-168, 65],  # Northwest corner (top-left)\n",
        "    [-168, 10],  # Southwest corner (bottom-left)\n",
        "    [-52, 10],   # Southeast corner (bottom-right)\n",
        "    [-52, 65],   # Northeast corner (top-right)\n",
        "])\n",
        "\n",
        "# Filter the collection based on the ROI and time range\n",
        "modis_filtered = modis_collection.filterDate('2001-01-01', '2001-12-31')\n",
        "input = modis_filtered.median()\n",
        "# .clip(north_america_polygon)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use folium to visualize the imagery.\n",
        "mapid = input.getMapId({'bands': ['NDVI'], 'min': 0, 'max': 8000, 'palette': [\n",
        "    'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',\n",
        "    '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',\n",
        "    '012e01', '011d01', '011301'\n",
        "  ]})\n",
        "map = folium.Map(location=[49.2827, -123.1207])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='NDVI',\n",
        "  ).add_to(map)\n",
        "\n",
        "mapid = input.getMapId({'bands': ['EVI'], 'min': 0, 'max': 8000, 'palette': [\n",
        "    'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',\n",
        "    '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',\n",
        "    '012e01', '011d01', '011301'\n",
        "  ]})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='EVI',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "yXH0v0pHfX5q",
        "outputId": "c4b4df34-5733-4942-d076-0cd04a8e1fe9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7a7ac097a080>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_34fd99dd9cdb13e756a1a76a27e7bffa {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_34fd99dd9cdb13e756a1a76a27e7bffa&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_34fd99dd9cdb13e756a1a76a27e7bffa = L.map(\n",
              "                &quot;map_34fd99dd9cdb13e756a1a76a27e7bffa&quot;,\n",
              "                {\n",
              "                    center: [49.2827, -123.1207],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_57dd07811b46bbb1ace22d7c64468557 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_34fd99dd9cdb13e756a1a76a27e7bffa);\n",
              "        \n",
              "    \n",
              "            var tile_layer_6ee7093236ab88da0b102ce8609f90cc = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/96ea2441849909927b679b1200660daf-e46ef578771a3eda56874086e3394eab/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_34fd99dd9cdb13e756a1a76a27e7bffa);\n",
              "        \n",
              "    \n",
              "            var tile_layer_65c1c0635c7a5430e5d0a9b86d8fb2d0 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/7ae6331bc0b15e14eaab0ced6923c707-14604031a17bcb14048ee1a30791cbe5/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_34fd99dd9cdb13e756a1a76a27e7bffa);\n",
              "        \n",
              "    \n",
              "            var layer_control_7515bf2ac3fa8fcf41b4b6a1b1be35f9 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_57dd07811b46bbb1ace22d7c64468557,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;NDVI&quot; : tile_layer_6ee7093236ab88da0b102ce8609f90cc,\n",
              "                    &quot;EVI&quot; : tile_layer_65c1c0635c7a5430e5d0a9b86d8fb2d0,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_7515bf2ac3fa8fcf41b4b6a1b1be35f9.base_layers,\n",
              "                layer_control_7515bf2ac3fa8fcf41b4b6a1b1be35f9.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_34fd99dd9cdb13e756a1a76a27e7bffa);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the response (NPP) from the MODIS Net Primary Production CONUS dataset. Display to check."
      ],
      "metadata": {
        "id": "d0n3qOnpgu7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "npp_collection = ee.ImageCollection('UMT/NTSG/v2/MODIS/NPP')\n",
        "npp_filtered = npp_collection.filterDate('2001-01-01', '2001-12-31')\n",
        "output = npp_filtered.median().select('annualNPP').divide(65535).float()\n",
        "\n",
        "mapid = output.getMapId({'min': 0, 'max': 1, 'palette': ['bbe029', '0a9501', '074b03']})\n",
        "map = folium.Map(location=[38., -122.5])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='npp',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "IVq4oOzMgwd4",
        "outputId": "d0f390ae-f5da-4958-abd5-b130bc00e5c5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7a7ac0928a60>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_05ebddd577186f9b85fa99dd3b561cda {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_05ebddd577186f9b85fa99dd3b561cda&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_05ebddd577186f9b85fa99dd3b561cda = L.map(\n",
              "                &quot;map_05ebddd577186f9b85fa99dd3b561cda&quot;,\n",
              "                {\n",
              "                    center: [38.0, -122.5],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_5eb57e127a366fcb0b5f4b7963c4188a = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_05ebddd577186f9b85fa99dd3b561cda);\n",
              "        \n",
              "    \n",
              "            var tile_layer_c2d37fd08a6cd5a0cfade7310819c498 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/0d794ab8da16417dd479d4a780bfa6a6-9b1bf7399ad3c0e24241abca239e047b/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_05ebddd577186f9b85fa99dd3b561cda);\n",
              "        \n",
              "    \n",
              "            var layer_control_8c6add8b9be1b2ad9860b32e97e7dc38 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_5eb57e127a366fcb0b5f4b7963c4188a,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;npp&quot; : tile_layer_c2d37fd08a6cd5a0cfade7310819c498,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_8c6add8b9be1b2ad9860b32e97e7dc38.base_layers,\n",
              "                layer_control_8c6add8b9be1b2ad9860b32e97e7dc38.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_05ebddd577186f9b85fa99dd3b561cda);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stack the 2D images (Terra Vegetation Indices and MODIS Net Primary Production) to create a single image from which samples can be taken. Convert the image into an array image in which each pixel stores 256x256 patches of pixels for each band. To export training patches, convert a multi-band image to an array image using neighborhoodToArray(), then sample the image at points.\n"
      ],
      "metadata": {
        "id": "QOOIb0hjphjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featureStack = ee.Image.cat([\n",
        "  input.select(BANDS),\n",
        "  output.select(RESPONSE)\n",
        "]).float()\n",
        "list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "arrays = featureStack.neighborhoodToArray(kernel)"
      ],
      "metadata": {
        "id": "g36a-LDIpwgP"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use some pre-made geometries to sample the stack in strategic locations. Specifically, these are hand-made polygons in which to take the 256x256 samples. Display the sampling polygons on a map, red for training polygons, blue for evaluation."
      ],
      "metadata": {
        "id": "Imo_xf43sfzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainingPolys = ee.FeatureCollection('projects/google/DemoTrainingGeometries')\n",
        "evalPolys = ee.FeatureCollection('projects/google/DemoEvalGeometries')\n",
        "\n",
        "polyImage = ee.Image(0).byte().paint(trainingPolys, 1).paint(evalPolys, 2)\n",
        "polyImage = polyImage.updateMask(polyImage)\n",
        "\n",
        "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
        "map = folium.Map(location=[38., -100.], zoom_start=5)\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='training polygons',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "z7FA6g2aseu0",
        "outputId": "68b3c63c-c7cc-4cca-eb42-de0ddf659f6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7b96c6c59c60>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_7ffbd90f48b998cfd961dae091d5117b {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_7ffbd90f48b998cfd961dae091d5117b&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_7ffbd90f48b998cfd961dae091d5117b = L.map(\n",
              "                &quot;map_7ffbd90f48b998cfd961dae091d5117b&quot;,\n",
              "                {\n",
              "                    center: [38.0, -100.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 5,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_d33813ad923a31647921020c465b9158 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_7ffbd90f48b998cfd961dae091d5117b);\n",
              "        \n",
              "    \n",
              "            var tile_layer_8cd5c17dcef881497745e2ea443a342e = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/3959de45a944ccc4fa1fadd758c8f8c9-0bd02567b45ae6ce757292dab6977ae4/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_7ffbd90f48b998cfd961dae091d5117b);\n",
              "        \n",
              "    \n",
              "            var layer_control_f0efd7ab67b67f8adb2af13ea2199222 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_d33813ad923a31647921020c465b9158,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;training polygons&quot; : tile_layer_8cd5c17dcef881497745e2ea443a342e,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_f0efd7ab67b67f8adb2af13ea2199222.base_layers,\n",
              "                layer_control_f0efd7ab67b67f8adb2af13ea2199222.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_7ffbd90f48b998cfd961dae091d5117b);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV890gPHeZqz"
      },
      "source": [
        "# Sampling\n",
        "\n",
        "The mapped data look reasonable so take a sample from each polygon and merge the results into a single export.  The key step is sampling the array image at points, to get all the pixels in a 256x256 neighborhood at each point.  To build the training and testing data for the FCNN, you export a single TFRecord file that contains patches of pixel values in each record.  You do NOT need to export each training/testing patch to a different image.  Since each record potentially contains a lot of data (especially with big patches or many input bands), some manual sharding of the computation is necessary to avoid the `computed value too large` error.  Specifically, the following code takes multiple (smaller) samples within each geometry, merging the results to get a single export."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyRpvwENxE-A",
        "cellView": "both"
      },
      "source": [
        "# Convert the feature collections to lists for iteration.\n",
        "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
        "evalPolysList = evalPolys.toList(evalPolys.size())\n",
        "\n",
        "# These numbers determined experimentally.\n",
        "n = 200 # Number of shards in each polygon.\n",
        "N = 2000 # Total sample size in each polygon.\n",
        "\n",
        "# Export all the training data (in many pieces), with one task\n",
        "# per geometry.\n",
        "for g in range(trainingPolys.size().getInfo()):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "  for i in range(n):\n",
        "    sample = arrays.sample(\n",
        "      region = ee.Feature(trainingPolysList.get(g)).geometry(),\n",
        "      scale = 30,\n",
        "      numPixels = N / n, # Size of the shard.\n",
        "      seed = i,\n",
        "      tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "\n",
        "  desc = 'training_patches' + '_g' + str(g)\n",
        "  task = ee.batch.Export.table.toDrive(\n",
        "    collection = geomSample,\n",
        "    description = desc,\n",
        "    folder = FOLDER,\n",
        "    fileNamePrefix = desc,\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "# Export all the evaluation data.\n",
        "for g in range(evalPolys.size().getInfo()):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "  for i in range(n):\n",
        "    sample = arrays.sample(\n",
        "      region = ee.Feature(evalPolysList.get(g)).geometry(),\n",
        "      scale = 30,\n",
        "      numPixels = N / n,\n",
        "      seed = i,\n",
        "      tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "\n",
        "  desc = 'eval_patches' + '_g' + str(g)\n",
        "  task = ee.batch.Export.table.toDrive(\n",
        "    collection = geomSample,\n",
        "    description = desc,\n",
        "    folder = FOLDER,\n",
        "    fileNamePrefix = desc,\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training data\n",
        "\n",
        "Load the data exported from Earth Engine into a `tf.data.Dataset`.  The following are helper functions for that."
      ],
      "metadata": {
        "id": "maGODNK_0Lxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "  Returns:\n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "  \"\"\"\n",
        "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "\n",
        "\n",
        "def to_tuple(inputs):\n",
        "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "  Args:\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "  Returns:\n",
        "    A tuple of (inputs, outputs).\n",
        "  \"\"\"\n",
        "  inputsList = [inputs.get(key) for key in FEATURES]\n",
        "  stacked = tf.stack(inputsList, axis=0)\n",
        "  # Convert from CHW to HWC\n",
        "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
        "\n",
        "\n",
        "def get_dataset(pattern):\n",
        "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
        "  Get all the files matching the pattern, parse and convert to tuple.\n",
        "  Args:\n",
        "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "  Returns:\n",
        "    A tf.data.Dataset\n",
        "  \"\"\"\n",
        "  glob = tf.io.gfile.glob(pattern)\n",
        "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
        "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "42rjNI3h0VUh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the helpers to read in the training dataset.  Print the first record to check."
      ],
      "metadata": {
        "id": "P0w9Oc6o1BWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import train\n",
        "def get_training_dataset():\n",
        "\t\"\"\"Get the preprocessed training dataset\n",
        "  Returns:\n",
        "    A tf.data.Dataset of training data.\n",
        "  \"\"\"\n",
        "\troot_dir = 'drive/My Drive/'\n",
        "\tglob = root_dir + FOLDER + '/' + 'training_patches' + '*'\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "training = get_training_dataset()\n",
        "print(iter(training.take(1)).next())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FtJDBGn1BER",
        "outputId": "b8c44a49-2dec-4ae6-c79e-26067dfa9b24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(16, 256, 256, 2), dtype=float32, numpy=\n",
            "array([[[[3549., 1654.],\n",
            "         [3549., 1654.],\n",
            "         [3549., 1654.],\n",
            "         ...,\n",
            "         [2495., 1063.],\n",
            "         [2495., 1063.],\n",
            "         [2495., 1063.]],\n",
            "\n",
            "        [[3405., 1654.],\n",
            "         [3405., 1654.],\n",
            "         [3405., 1654.],\n",
            "         ...,\n",
            "         [2435., 1062.],\n",
            "         [2435., 1062.],\n",
            "         [2435., 1062.]],\n",
            "\n",
            "        [[3405., 1654.],\n",
            "         [3405., 1654.],\n",
            "         [3405., 1654.],\n",
            "         ...,\n",
            "         [2435., 1062.],\n",
            "         [2394., 1109.],\n",
            "         [2394., 1109.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[2520., 1106.],\n",
            "         [2520., 1106.],\n",
            "         [2520., 1106.],\n",
            "         ...,\n",
            "         [2842., 1213.],\n",
            "         [2842., 1213.],\n",
            "         [2842., 1213.]],\n",
            "\n",
            "        [[2520., 1106.],\n",
            "         [2520., 1106.],\n",
            "         [2520., 1106.],\n",
            "         ...,\n",
            "         [2842., 1213.],\n",
            "         [2842., 1213.],\n",
            "         [2745., 1298.]],\n",
            "\n",
            "        [[2520., 1106.],\n",
            "         [2520., 1106.],\n",
            "         [2520., 1106.],\n",
            "         ...,\n",
            "         [2842., 1213.],\n",
            "         [2745., 1298.],\n",
            "         [2745., 1298.]]],\n",
            "\n",
            "\n",
            "       [[[4631., 2192.],\n",
            "         [4631., 2192.],\n",
            "         [4631., 2192.],\n",
            "         ...,\n",
            "         [3902., 2204.],\n",
            "         [3902., 2204.],\n",
            "         [3902., 2204.]],\n",
            "\n",
            "        [[4631., 2192.],\n",
            "         [4631., 2192.],\n",
            "         [4631., 2192.],\n",
            "         ...,\n",
            "         [3902., 2204.],\n",
            "         [3961., 1988.],\n",
            "         [3961., 1988.]],\n",
            "\n",
            "        [[4631., 2192.],\n",
            "         [4631., 2192.],\n",
            "         [4631., 2192.],\n",
            "         ...,\n",
            "         [3961., 1988.],\n",
            "         [3961., 1988.],\n",
            "         [3961., 1988.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[3458., 1803.],\n",
            "         [3458., 1803.],\n",
            "         [3458., 1803.],\n",
            "         ...,\n",
            "         [4148., 2150.],\n",
            "         [4148., 2150.],\n",
            "         [4148., 2150.]],\n",
            "\n",
            "        [[3458., 1803.],\n",
            "         [3458., 1803.],\n",
            "         [3463., 2232.],\n",
            "         ...,\n",
            "         [4148., 2150.],\n",
            "         [4148., 2150.],\n",
            "         [4148., 2150.]],\n",
            "\n",
            "        [[3458., 1803.],\n",
            "         [3463., 2232.],\n",
            "         [3463., 2232.],\n",
            "         ...,\n",
            "         [4148., 2150.],\n",
            "         [4148., 2150.],\n",
            "         [4148., 2150.]]],\n",
            "\n",
            "\n",
            "       [[[3005., 1447.],\n",
            "         [3005., 1447.],\n",
            "         [3005., 1447.],\n",
            "         ...,\n",
            "         [3055., 1586.],\n",
            "         [3055., 1586.],\n",
            "         [3055., 1586.]],\n",
            "\n",
            "        [[3005., 1447.],\n",
            "         [3005., 1447.],\n",
            "         [3005., 1447.],\n",
            "         ...,\n",
            "         [3055., 1586.],\n",
            "         [3055., 1586.],\n",
            "         [3055., 1586.]],\n",
            "\n",
            "        [[3005., 1447.],\n",
            "         [3005., 1447.],\n",
            "         [3005., 1447.],\n",
            "         ...,\n",
            "         [3055., 1586.],\n",
            "         [3055., 1586.],\n",
            "         [3055., 1586.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[3129., 1366.],\n",
            "         [3129., 1366.],\n",
            "         [3129., 1366.],\n",
            "         ...,\n",
            "         [4013., 2149.],\n",
            "         [4013., 2149.],\n",
            "         [4013., 2149.]],\n",
            "\n",
            "        [[3129., 1366.],\n",
            "         [3129., 1366.],\n",
            "         [3129., 1366.],\n",
            "         ...,\n",
            "         [4013., 2149.],\n",
            "         [4013., 2149.],\n",
            "         [4013., 2149.]],\n",
            "\n",
            "        [[2885., 1329.],\n",
            "         [2885., 1329.],\n",
            "         [2885., 1329.],\n",
            "         ...,\n",
            "         [3493., 1619.],\n",
            "         [3493., 1619.],\n",
            "         [3493., 1619.]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[6639., 4472.],\n",
            "         [6639., 4472.],\n",
            "         [6639., 4472.],\n",
            "         ...,\n",
            "         [5181., 3605.],\n",
            "         [5181., 3605.],\n",
            "         [5181., 3605.]],\n",
            "\n",
            "        [[7854., 5495.],\n",
            "         [7854., 5495.],\n",
            "         [7854., 5495.],\n",
            "         ...,\n",
            "         [6160., 4275.],\n",
            "         [6160., 4275.],\n",
            "         [6160., 4275.]],\n",
            "\n",
            "        [[7854., 5495.],\n",
            "         [7854., 5495.],\n",
            "         [7494., 5915.],\n",
            "         ...,\n",
            "         [6160., 4275.],\n",
            "         [6160., 4275.],\n",
            "         [6616., 4709.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[6287., 4174.],\n",
            "         [6287., 4174.],\n",
            "         [6287., 4174.],\n",
            "         ...,\n",
            "         [4587., 3213.],\n",
            "         [4587., 3213.],\n",
            "         [4587., 3213.]],\n",
            "\n",
            "        [[6287., 4174.],\n",
            "         [6287., 4174.],\n",
            "         [6287., 4174.],\n",
            "         ...,\n",
            "         [4587., 3213.],\n",
            "         [4587., 3213.],\n",
            "         [4587., 3213.]],\n",
            "\n",
            "        [[6287., 4174.],\n",
            "         [6755., 4997.],\n",
            "         [6755., 4997.],\n",
            "         ...,\n",
            "         [4587., 3213.],\n",
            "         [4587., 3213.],\n",
            "         [4384., 2761.]]],\n",
            "\n",
            "\n",
            "       [[[4232., 1943.],\n",
            "         [4232., 1943.],\n",
            "         [4309., 2212.],\n",
            "         ...,\n",
            "         [2889., 1250.],\n",
            "         [2889., 1250.],\n",
            "         [2889., 1250.]],\n",
            "\n",
            "        [[4309., 2212.],\n",
            "         [4309., 2212.],\n",
            "         [4309., 2212.],\n",
            "         ...,\n",
            "         [2889., 1250.],\n",
            "         [2889., 1250.],\n",
            "         [2889., 1250.]],\n",
            "\n",
            "        [[4232., 1806.],\n",
            "         [4232., 1806.],\n",
            "         [4232., 1806.],\n",
            "         ...,\n",
            "         [2792.,  998.],\n",
            "         [2792.,  998.],\n",
            "         [2792.,  998.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[3763., 1767.],\n",
            "         [3763., 1767.],\n",
            "         [3763., 1767.],\n",
            "         ...,\n",
            "         [3522., 1607.],\n",
            "         [3522., 1607.],\n",
            "         [3522., 1607.]],\n",
            "\n",
            "        [[3763., 1767.],\n",
            "         [3763., 1767.],\n",
            "         [3763., 1767.],\n",
            "         ...,\n",
            "         [3522., 1607.],\n",
            "         [3522., 1607.],\n",
            "         [3522., 1607.]],\n",
            "\n",
            "        [[3763., 1767.],\n",
            "         [3763., 1767.],\n",
            "         [3763., 1767.],\n",
            "         ...,\n",
            "         [3522., 1607.],\n",
            "         [3522., 1607.],\n",
            "         [3522., 1607.]]],\n",
            "\n",
            "\n",
            "       [[[5007., 2108.],\n",
            "         [5007., 2108.],\n",
            "         [4767., 1890.],\n",
            "         ...,\n",
            "         [4581., 1719.],\n",
            "         [4581., 1719.],\n",
            "         [4581., 1719.]],\n",
            "\n",
            "        [[4767., 1890.],\n",
            "         [4767., 1890.],\n",
            "         [4767., 1890.],\n",
            "         ...,\n",
            "         [4581., 1719.],\n",
            "         [5769., 2879.],\n",
            "         [5769., 2879.]],\n",
            "\n",
            "        [[4767., 1890.],\n",
            "         [4767., 1890.],\n",
            "         [4767., 1890.],\n",
            "         ...,\n",
            "         [5769., 2879.],\n",
            "         [5769., 2879.],\n",
            "         [5769., 2879.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[4407., 1772.],\n",
            "         [4407., 1772.],\n",
            "         [4407., 1772.],\n",
            "         ...,\n",
            "         [4258., 1744.],\n",
            "         [4221., 1701.],\n",
            "         [4221., 1701.]],\n",
            "\n",
            "        [[4407., 1772.],\n",
            "         [4407., 1772.],\n",
            "         [4407., 1772.],\n",
            "         ...,\n",
            "         [4221., 1701.],\n",
            "         [4221., 1701.],\n",
            "         [4221., 1701.]],\n",
            "\n",
            "        [[4407., 1772.],\n",
            "         [4407., 1772.],\n",
            "         [4407., 1772.],\n",
            "         ...,\n",
            "         [4221., 1701.],\n",
            "         [4221., 1701.],\n",
            "         [4221., 1701.]]]], dtype=float32)>, <tf.Tensor: shape=(16, 256, 256, 1), dtype=float32, numpy=\n",
            "array([[[[0.15817502],\n",
            "         [0.14752422],\n",
            "         [0.14752422],\n",
            "         ...,\n",
            "         [0.15078965],\n",
            "         [0.15078965],\n",
            "         [0.14709698]],\n",
            "\n",
            "        [[0.15817502],\n",
            "         [0.14752422],\n",
            "         [0.14752422],\n",
            "         ...,\n",
            "         [0.15078965],\n",
            "         [0.15078965],\n",
            "         [0.14709698]],\n",
            "\n",
            "        [[0.15817502],\n",
            "         [0.14752422],\n",
            "         [0.14752422],\n",
            "         ...,\n",
            "         [0.15078965],\n",
            "         [0.15078965],\n",
            "         [0.14709698]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.13452354],\n",
            "         [0.13105974],\n",
            "         [0.13105974],\n",
            "         ...,\n",
            "         [0.1401999 ],\n",
            "         [0.1401999 ],\n",
            "         [0.14279392]],\n",
            "\n",
            "        [[0.13452354],\n",
            "         [0.13105974],\n",
            "         [0.13105974],\n",
            "         ...,\n",
            "         [0.1401999 ],\n",
            "         [0.1401999 ],\n",
            "         [0.14279392]],\n",
            "\n",
            "        [[0.13452354],\n",
            "         [0.13105974],\n",
            "         [0.13105974],\n",
            "         ...,\n",
            "         [0.1401999 ],\n",
            "         [0.1401999 ],\n",
            "         [0.14279392]]],\n",
            "\n",
            "\n",
            "       [[[0.1832456 ],\n",
            "         [0.1832456 ],\n",
            "         [0.1832456 ],\n",
            "         ...,\n",
            "         [0.16124208],\n",
            "         [0.16124208],\n",
            "         [0.16124208]],\n",
            "\n",
            "        [[0.1832456 ],\n",
            "         [0.1832456 ],\n",
            "         [0.1832456 ],\n",
            "         ...,\n",
            "         [0.16124208],\n",
            "         [0.16124208],\n",
            "         [0.16124208]],\n",
            "\n",
            "        [[0.1832456 ],\n",
            "         [0.1832456 ],\n",
            "         [0.1832456 ],\n",
            "         ...,\n",
            "         [0.16124208],\n",
            "         [0.16124208],\n",
            "         [0.16124208]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.1634699 ],\n",
            "         [0.1634699 ],\n",
            "         [0.1634699 ],\n",
            "         ...,\n",
            "         [0.12330816],\n",
            "         [0.12330816],\n",
            "         [0.12330816]],\n",
            "\n",
            "        [[0.1634699 ],\n",
            "         [0.1634699 ],\n",
            "         [0.1634699 ],\n",
            "         ...,\n",
            "         [0.12330816],\n",
            "         [0.12330816],\n",
            "         [0.12330816]],\n",
            "\n",
            "        [[0.1724117 ],\n",
            "         [0.1724117 ],\n",
            "         [0.1724117 ],\n",
            "         ...,\n",
            "         [0.18751812],\n",
            "         [0.18751812],\n",
            "         [0.18751812]]],\n",
            "\n",
            "\n",
            "       [[[0.16224918],\n",
            "         [0.16224918],\n",
            "         [0.16224918],\n",
            "         ...,\n",
            "         [0.16173038],\n",
            "         [0.16173038],\n",
            "         [0.16173038]],\n",
            "\n",
            "        [[0.16224918],\n",
            "         [0.16224918],\n",
            "         [0.16224918],\n",
            "         ...,\n",
            "         [0.16173038],\n",
            "         [0.16173038],\n",
            "         [0.16173038]],\n",
            "\n",
            "        [[0.16224918],\n",
            "         [0.16224918],\n",
            "         [0.16224918],\n",
            "         ...,\n",
            "         [0.16173038],\n",
            "         [0.16173038],\n",
            "         [0.16173038]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.16197452],\n",
            "         [0.16197452],\n",
            "         [0.16197452],\n",
            "         ...,\n",
            "         [0.15533684],\n",
            "         [0.15533684],\n",
            "         [0.15533684]],\n",
            "\n",
            "        [[0.16197452],\n",
            "         [0.16197452],\n",
            "         [0.16197452],\n",
            "         ...,\n",
            "         [0.15533684],\n",
            "         [0.15533684],\n",
            "         [0.15533684]],\n",
            "\n",
            "        [[0.16197452],\n",
            "         [0.16197452],\n",
            "         [0.16197452],\n",
            "         ...,\n",
            "         [0.15533684],\n",
            "         [0.15533684],\n",
            "         [0.15533684]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[0.15159838],\n",
            "         [0.15159838],\n",
            "         [0.15159838],\n",
            "         ...,\n",
            "         [0.23073167],\n",
            "         [0.23073167],\n",
            "         [0.23073167]],\n",
            "\n",
            "        [[0.15159838],\n",
            "         [0.15159838],\n",
            "         [0.15159838],\n",
            "         ...,\n",
            "         [0.23073167],\n",
            "         [0.23073167],\n",
            "         [0.23073167]],\n",
            "\n",
            "        [[0.15159838],\n",
            "         [0.15159838],\n",
            "         [0.15159838],\n",
            "         ...,\n",
            "         [0.23073167],\n",
            "         [0.23073167],\n",
            "         [0.23073167]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.13258564],\n",
            "         [0.13258564],\n",
            "         [0.13258564],\n",
            "         ...,\n",
            "         [0.16949722],\n",
            "         [0.16949722],\n",
            "         [0.16949722]],\n",
            "\n",
            "        [[0.13258564],\n",
            "         [0.13258564],\n",
            "         [0.13258564],\n",
            "         ...,\n",
            "         [0.16949722],\n",
            "         [0.16949722],\n",
            "         [0.16949722]],\n",
            "\n",
            "        [[0.13734646],\n",
            "         [0.13734646],\n",
            "         [0.13734646],\n",
            "         ...,\n",
            "         [0.20094606],\n",
            "         [0.20094606],\n",
            "         [0.20094606]]],\n",
            "\n",
            "\n",
            "       [[[0.16849013],\n",
            "         [0.16849013],\n",
            "         [0.16849013],\n",
            "         ...,\n",
            "         [0.15930419],\n",
            "         [0.15930419],\n",
            "         [0.15608454]],\n",
            "\n",
            "        [[0.16849013],\n",
            "         [0.16849013],\n",
            "         [0.16849013],\n",
            "         ...,\n",
            "         [0.15930419],\n",
            "         [0.15930419],\n",
            "         [0.15608454]],\n",
            "\n",
            "        [[0.16849013],\n",
            "         [0.16849013],\n",
            "         [0.16849013],\n",
            "         ...,\n",
            "         [0.15930419],\n",
            "         [0.15930419],\n",
            "         [0.15608454]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.17935455],\n",
            "         [0.17935455],\n",
            "         [0.17935455],\n",
            "         ...,\n",
            "         [0.18095674],\n",
            "         [0.18095674],\n",
            "         [0.18852521]],\n",
            "\n",
            "        [[0.17935455],\n",
            "         [0.17935455],\n",
            "         [0.17935455],\n",
            "         ...,\n",
            "         [0.18095674],\n",
            "         [0.18095674],\n",
            "         [0.18852521]],\n",
            "\n",
            "        [[0.17935455],\n",
            "         [0.17935455],\n",
            "         [0.17935455],\n",
            "         ...,\n",
            "         [0.18095674],\n",
            "         [0.18095674],\n",
            "         [0.18852521]]],\n",
            "\n",
            "\n",
            "       [[[0.12889296],\n",
            "         [0.12889296],\n",
            "         [0.12889296],\n",
            "         ...,\n",
            "         [0.12829785],\n",
            "         [0.12829785],\n",
            "         [0.12829785]],\n",
            "\n",
            "        [[0.12889296],\n",
            "         [0.12889296],\n",
            "         [0.12889296],\n",
            "         ...,\n",
            "         [0.12829785],\n",
            "         [0.12829785],\n",
            "         [0.12829785]],\n",
            "\n",
            "        [[0.12889296],\n",
            "         [0.12889296],\n",
            "         [0.12889296],\n",
            "         ...,\n",
            "         [0.12829785],\n",
            "         [0.12829785],\n",
            "         [0.12829785]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.12559702],\n",
            "         [0.12559702],\n",
            "         [0.12559702],\n",
            "         ...,\n",
            "         [0.12222476],\n",
            "         [0.12222476],\n",
            "         [0.12222476]],\n",
            "\n",
            "        [[0.12677196],\n",
            "         [0.12677196],\n",
            "         [0.12677196],\n",
            "         ...,\n",
            "         [0.12278935],\n",
            "         [0.12278935],\n",
            "         [0.12278935]],\n",
            "\n",
            "        [[0.12677196],\n",
            "         [0.12677196],\n",
            "         [0.12677196],\n",
            "         ...,\n",
            "         [0.12278935],\n",
            "         [0.12278935],\n",
            "         [0.12278935]]]], dtype=float32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation data\n",
        "\n",
        "Now do the same thing to get an evaluation dataset.  Note that unlike the training dataset, the evaluation dataset has a batch size of 1, is not repeated and is not shuffled."
      ],
      "metadata": {
        "id": "beFseGNEWUpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_dataset():\n",
        "\t\"\"\"Get the preprocessed evaluation dataset\n",
        "  Returns:\n",
        "    A tf.data.Dataset of evaluation data.\n",
        "  \"\"\"\n",
        "\troot_dir = 'drive/My Drive/'\n",
        "\tglob = root_dir + FOLDER + '/' + 'eval_patches' + '*'\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.batch(1).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "evaluation = get_eval_dataset()\n",
        "evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbSPM_a8WX6Z",
        "outputId": "ce92e008-0bf7-40ae-f938-e9748bd2c301"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_RepeatDataset element_spec=(TensorSpec(shape=(None, 256, 256, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "Here we use the Keras implementation of the U-Net model.  The U-Net model takes 256x256 pixel patches as input and outputs per-pixel class probability, label or a continuous output.  We can implement the model essentially unmodified, but will use mean squared error loss on the sigmoidal output since we are treating this as a regression problem, rather than a classification problem.  Since impervious surface fraction is constrained to [0,1], with many values close to zero or one, a saturating activation function is suitable here."
      ],
      "metadata": {
        "id": "s7Mtrx_YXE28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.python.keras import layers\n",
        "# from tensorflow.python.keras import losses\n",
        "# from tensorflow.python.keras import models\n",
        "# from tensorflow.python.keras import metrics\n",
        "# from tensorflow.python.keras import optimizers\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = BatchNormalization()(encoder)\n",
        "\tencoder = Activation('relu')(encoder)\n",
        "\tencoder = Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = BatchNormalization()(encoder)\n",
        "\tencoder = Activation('relu')(encoder)\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = BatchNormalization()(decoder)\n",
        "\tdecoder = Activation('relu')(decoder)\n",
        "\tdecoder = Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = BatchNormalization()(decoder)\n",
        "\tdecoder = Activation('relu')(decoder)\n",
        "\tdecoder = Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = BatchNormalization()(decoder)\n",
        "\tdecoder = Activation('relu')(decoder)\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = Input(shape=[None, None, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
        "\n",
        "\tmodel = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER),\n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "NJr-VUE7XF08"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "\n",
        "Here we're going to train for 10 epochs.  For better accuracy, optimize this parameter, for example through [hyperparamter tuning](https://cloud.google.com/ml-engine/docs/tensorflow/using-hyperparameter-tuning)."
      ],
      "metadata": {
        "id": "YCqxtyDoXtQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = get_model()\n",
        "\n",
        "m.fit(\n",
        "    x=training,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE),\n",
        "    validation_data=evaluation,\n",
        "    validation_steps=EVAL_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36UBzMYMXuGp",
        "outputId": "f3c74fc1-4318-442b-99e1-8f8cff2fe883"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 596s 561ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 555s 555ms/step - loss: 0.0050 - root_mean_squared_error: 0.0708 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 529s 529ms/step - loss: 0.0043 - root_mean_squared_error: 0.0659 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0685\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 555s 555ms/step - loss: 0.0043 - root_mean_squared_error: 0.0656 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 524s 524ms/step - loss: 0.0040 - root_mean_squared_error: 0.0631 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0665\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 552s 552ms/step - loss: 0.0039 - root_mean_squared_error: 0.0626 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0631\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 550s 550ms/step - loss: 0.0040 - root_mean_squared_error: 0.0630 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0586\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 550s 550ms/step - loss: 0.0037 - root_mean_squared_error: 0.0606 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 550s 550ms/step - loss: 0.0038 - root_mean_squared_error: 0.0613 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 521s 521ms/step - loss: 0.0038 - root_mean_squared_error: 0.0616 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0562\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b96363e59c0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the model's architecture\n",
        "m.summary()\n",
        "\n",
        "# Save the weights\n",
        "m.save_weights('drive/My Drive/carbon_mapping/my_checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odheK3XKblhh",
        "outputId": "54d9c32a-02a0-4217-802f-00e4a2112fac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 2)]                                                              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, None, None,   608         ['input_1[0][0]']                \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, None, None,   128        ['conv2d[0][0]']                 \n",
            " alization)                     32)                                                               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, None, None,   0           ['batch_normalization[0][0]']    \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, None, None,   9248        ['activation[0][0]']             \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, None, None,   128        ['conv2d_1[0][0]']               \n",
            " rmalization)                   32)                                                               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, None, None,   0           ['batch_normalization_1[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, None, None,   0           ['activation_1[0][0]']           \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, None, None,   18496       ['max_pooling2d[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, None, None,   256        ['conv2d_2[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, None, None,   0           ['batch_normalization_2[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, None, None,   36928       ['activation_2[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, None, None,   256        ['conv2d_3[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, None, None,   0           ['batch_normalization_3[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, None, None,   0          ['activation_3[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, None, None,   73856       ['max_pooling2d_1[0][0]']        \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, None, None,   512        ['conv2d_4[0][0]']               \n",
            " rmalization)                   128)                                                              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, None, None,   0           ['batch_normalization_4[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, None, None,   147584      ['activation_4[0][0]']           \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, None, None,   512        ['conv2d_5[0][0]']               \n",
            " rmalization)                   128)                                                              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, None, None,   0           ['batch_normalization_5[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, None, None,   0          ['activation_5[0][0]']           \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, None, None,   295168      ['max_pooling2d_2[0][0]']        \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, None, None,   1024       ['conv2d_6[0][0]']               \n",
            " rmalization)                   256)                                                              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, None, None,   0           ['batch_normalization_6[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, None, None,   590080      ['activation_6[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, None, None,   1024       ['conv2d_7[0][0]']               \n",
            " rmalization)                   256)                                                              \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, None, None,   0           ['batch_normalization_7[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, None, None,   0          ['activation_7[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, None, None,   1180160     ['max_pooling2d_3[0][0]']        \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, None, None,   2048       ['conv2d_8[0][0]']               \n",
            " rmalization)                   512)                                                              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, None, None,   0           ['batch_normalization_8[0][0]']  \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, None, None,   2359808     ['activation_8[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, None, None,   2048       ['conv2d_9[0][0]']               \n",
            " rmalization)                   512)                                                              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, None, None,   0           ['batch_normalization_9[0][0]']  \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, None, None,   0          ['activation_9[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, None, None,   4719616     ['max_pooling2d_4[0][0]']        \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, None, None,   4096       ['conv2d_10[0][0]']              \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, None, None,   0           ['batch_normalization_10[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, None, None,   9438208     ['activation_10[0][0]']          \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, None, None,   4096       ['conv2d_11[0][0]']              \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, None, None,   0           ['batch_normalization_11[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, None, None,   2097664    ['activation_11[0][0]']          \n",
            " ose)                           512)                                                              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, None,   0           ['activation_9[0][0]',           \n",
            "                                1024)                             'conv2d_transpose[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, None, None,   4096       ['concatenate[0][0]']            \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, None, None,   0           ['batch_normalization_12[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, None, None,   4719104     ['activation_12[0][0]']          \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, None, None,   2048       ['conv2d_12[0][0]']              \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, None, None,   0           ['batch_normalization_13[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, None, None,   2359808     ['activation_13[0][0]']          \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, None, None,   2048       ['conv2d_13[0][0]']              \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, None, None,   0           ['batch_normalization_14[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, None, None,   524544     ['activation_14[0][0]']          \n",
            " spose)                         256)                                                              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, None, None,   0           ['activation_7[0][0]',           \n",
            "                                512)                              'conv2d_transpose_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, None, None,   2048       ['concatenate_1[0][0]']          \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, None, None,   0           ['batch_normalization_15[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, None, None,   1179904     ['activation_15[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, None, None,   1024       ['conv2d_14[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, None, None,   0           ['batch_normalization_16[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, None, None,   590080      ['activation_16[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, None, None,   1024       ['conv2d_15[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, None, None,   0           ['batch_normalization_17[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, None, None,   131200     ['activation_17[0][0]']          \n",
            " spose)                         128)                                                              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, None, None,   0           ['activation_5[0][0]',           \n",
            "                                256)                              'conv2d_transpose_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, None, None,   1024       ['concatenate_2[0][0]']          \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, None, None,   0           ['batch_normalization_18[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, None, None,   295040      ['activation_18[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, None, None,   512        ['conv2d_16[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, None, None,   0           ['batch_normalization_19[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, None, None,   147584      ['activation_19[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, None, None,   512        ['conv2d_17[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, None, None,   0           ['batch_normalization_20[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, None, None,   32832      ['activation_20[0][0]']          \n",
            " spose)                         64)                                                               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, None, None,   0           ['activation_3[0][0]',           \n",
            "                                128)                              'conv2d_transpose_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, None, None,   512        ['concatenate_3[0][0]']          \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, None, None,   0           ['batch_normalization_21[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, None, None,   73792       ['activation_21[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, None, None,   256        ['conv2d_18[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, None, None,   0           ['batch_normalization_22[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, None, None,   36928       ['activation_22[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, None, None,   256        ['conv2d_19[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, None, None,   0           ['batch_normalization_23[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, None, None,   8224       ['activation_23[0][0]']          \n",
            " spose)                         32)                                                               \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, None, None,   0           ['activation_1[0][0]',           \n",
            "                                64)                               'conv2d_transpose_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, None, None,   256        ['concatenate_4[0][0]']          \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, None, None,   0           ['batch_normalization_24[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, None, None,   18464       ['activation_24[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, None, None,   128        ['conv2d_20[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, None, None,   0           ['batch_normalization_25[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, None, None,   9248        ['activation_25[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, None, None,   128        ['conv2d_21[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, None, None,   0           ['batch_normalization_26[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, None, None,   33          ['activation_26[0][0]']          \n",
            "                                1)                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,126,209\n",
            "Trainable params: 31,110,209\n",
            "Non-trainable params: 16,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Restore the weights\n",
        "m.load_weights('drive/My Drive/carbon_mapping/my_checkpoint')\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = m.evaluate(x=evaluation, verbose=2, steps=1000)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlZiqia4dSv4",
        "outputId": "4e9cf70e-35c1-45c5-c8b9-6efbc1f294a5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/1000 - 14s - loss: 0.0051 - root_mean_squared_error: 0.0714 - 14s/epoch - 14ms/step\n",
            "Restored model, accuracy:  7.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction\n",
        "\n",
        "The prediction pipeline is:\n",
        "\n",
        "1.  Export imagery on which to do predictions from Earth Engine in TFRecord format to a Cloud Storage bucket.\n",
        "2.  Use the trained model to make the predictions.\n",
        "3.  Write the predictions to a TFRecord file in a Cloud Storage.\n",
        "4.  Upload the predictions TFRecord file to Earth Engine.\n"
      ],
      "metadata": {
        "id": "Z7NnZU9KXPAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def doExport(out_image_base, kernel_buffer, region):\n",
        "  \"\"\"Run the image export task.  Block until complete.\n",
        "  \"\"\"\n",
        "  task = ee.batch.Export.image.toDrive(\n",
        "    image = image.select(BANDS),\n",
        "    description = out_image_base,\n",
        "    folder = FOLDER,\n",
        "    fileNamePrefix = out_image_base,\n",
        "    region = region.getInfo()['coordinates'],\n",
        "    scale = 30,\n",
        "    fileFormat = 'TFRecord',\n",
        "    maxPixels = 1e10,\n",
        "    formatOptions = {\n",
        "      'patchDimensions': KERNEL_SHAPE,\n",
        "      'kernelSize': kernel_buffer,\n",
        "      'compressed': True,\n",
        "      'maxFileSize': 104857600\n",
        "    }\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  # Block until the task completes.\n",
        "  print('Running image export to Google Drive...')\n",
        "  import time\n",
        "  while task.active():\n",
        "    time.sleep(30)\n",
        "\n",
        "  # Error condition\n",
        "  if task.status()['state'] != 'COMPLETED':\n",
        "    print('Error with image export.')\n",
        "  else:\n",
        "    print('Image export completed.')"
      ],
      "metadata": {
        "id": "pzCXrKiSXkgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doPrediction(out_image_base, user_folder, kernel_buffer, region):\n",
        "  \"\"\"Perform inference on exported imagery, upload to Earth Engine.\n",
        "  \"\"\"\n",
        "\n",
        "  print('Looking for TFRecord files...')\n",
        "\n",
        "  # Get a list of all the files in the output bucket.\n",
        "  filesList = !gsutil ls 'drive/My Drive/'{FOLDER}\n",
        "\n",
        "  # Get only the files generated by the image export.\n",
        "  exportFilesList = [s for s in filesList if out_image_base in s]\n",
        "\n",
        "  # Get the list of image files and the JSON mixer file.\n",
        "  imageFilesList = []\n",
        "  jsonFile = None\n",
        "  for f in exportFilesList:\n",
        "    if f.endswith('.tfrecord.gz'):\n",
        "      imageFilesList.append(f)\n",
        "    elif f.endswith('.json'):\n",
        "      jsonFile = f\n",
        "\n",
        "  # Make sure the files are in the right order.\n",
        "  imageFilesList.sort()\n",
        "\n",
        "  from pprint import pprint\n",
        "  pprint(imageFilesList)\n",
        "  print(jsonFile)\n",
        "\n",
        "  import json\n",
        "  # Load the contents of the mixer file to a JSON object.\n",
        "  jsonText = !gsutil cat {jsonFile}\n",
        "  # Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "  mixer = json.loads(jsonText.nlstr)\n",
        "  pprint(mixer)\n",
        "  patches = mixer['totalPatches']\n",
        "\n",
        "  # Get set up for prediction.\n",
        "  x_buffer = int(kernel_buffer[0] / 2)\n",
        "  y_buffer = int(kernel_buffer[1] / 2)\n",
        "\n",
        "  buffered_shape = [\n",
        "      KERNEL_SHAPE[0] + kernel_buffer[0],\n",
        "      KERNEL_SHAPE[1] + kernel_buffer[1]]\n",
        "\n",
        "  imageColumns = [\n",
        "    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32)\n",
        "      for k in BANDS\n",
        "  ]\n",
        "\n",
        "  imageFeaturesDict = dict(zip(BANDS, imageColumns))\n",
        "\n",
        "  def parse_image(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n",
        "\n",
        "  def toTupleImage(inputs):\n",
        "    inputsList = [inputs.get(key) for key in BANDS]\n",
        "    stacked = tf.stack(inputsList, axis=0)\n",
        "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "    return stacked\n",
        "\n",
        "   # Create a dataset from the TFRecord file(s) in Google Drive.\n",
        "  imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
        "  imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n",
        "  imageDataset = imageDataset.map(toTupleImage).batch(1)\n",
        "\n",
        "  # Perform inference.\n",
        "  print('Running predictions...')\n",
        "  predictions = m.predict(imageDataset, steps=patches, verbose=1)\n",
        "  # print(predictions[0])\n",
        "\n",
        "  print('Writing predictions...')\n",
        "  out_image_file = 'drive/My Drive/' + FOLDER + '/' + out_image_base + '.TFRecord'\n",
        "  writer = tf.io.TFRecordWriter(out_image_file)\n",
        "  patches = 0\n",
        "  for predictionPatch in predictions:\n",
        "    print('Writing patch ' + str(patches) + '...')\n",
        "    predictionPatch = predictionPatch[\n",
        "        x_buffer:x_buffer+KERNEL_SIZE, y_buffer:y_buffer+KERNEL_SIZE]\n",
        "\n",
        "    # Create an example.\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'impervious': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=predictionPatch.flatten()))\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example.\n",
        "    writer.write(example.SerializeToString())\n",
        "    patches += 1\n",
        "\n",
        "  writer.close()\n",
        "\n",
        "  # Start the upload.\n",
        "  out_image_asset = user_folder + '/' + out_image_base\n",
        "  !earthengine upload image --asset_id={out_image_asset} {out_image_file} {jsonFile}"
      ],
      "metadata": {
        "id": "Yf9hdBLeYTYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now there's all the code needed to run the prediction pipeline, all that remains is to specify the output region in which to do the prediction, the names of the output files, where to put them, and the shape of the outputs.  In terms of the shape, the model is trained on 256x256 patches, but can work (in theory) on any patch that's big enough with even dimensions ([reference](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)).  Because of tile boundary artifacts, give the model slightly larger patches for prediction, then clip out the middle 256x256 patch.  This is controlled with a kernel buffer, half the size of which will extend beyond the kernel buffer.  For example, specifying a 128x128 kernel will append 64 pixels on each side of the patch, to ensure that the pixels in the output are taken from inputs completely covered by the kernel."
      ],
      "metadata": {
        "id": "ImGAjvlBZ8Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output assets folder: YOUR FOLDER\n",
        "user_folder = 'users/username' # INSERT YOUR FOLDER HERE.\n",
        "\n",
        "# Base file name to use for TFRecord files and assets.\n",
        "bj_image_base = 'FCNN_demo_beijing_384_'\n",
        "# Half this will extend on the sides of each patch.\n",
        "bj_kernel_buffer = [128, 128]\n",
        "# Beijing\n",
        "bj_region = ee.Geometry.Polygon(\n",
        "        [[[115.9662455210937, 40.121362012835235],\n",
        "          [115.9662455210937, 39.64293313749715],\n",
        "          [117.01818643906245, 39.64293313749715],\n",
        "          [117.01818643906245, 40.121362012835235]]], None, False)"
      ],
      "metadata": {
        "id": "DH2WryDZZ84p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the export.\n",
        "doExport(bj_image_base, bj_kernel_buffer, bj_region)"
      ],
      "metadata": {
        "id": "At-jt4h0aNCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the prediction.\n",
        "doPrediction(bj_image_base, user_folder, bj_kernel_buffer, bj_region)"
      ],
      "metadata": {
        "id": "M6_b6UqGaNq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the output\n",
        "\n",
        "One the data has been exported, the model has made predictions and the predictions have been written to a file, and the image imported to Earth Engine, it's possible to display the resultant Earth Engine asset.  Here, display the impervious area predictions over Beijing, China."
      ],
      "metadata": {
        "id": "NttHsWDVaPu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_image = ee.Image(user_folder + '/' + bj_image_base)\n",
        "mapid = out_image.getMapId({'min': 0, 'max': 1})\n",
        "map = folium.Map(location=[39.898, 116.5097])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='predicted impervious',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "id": "4qhDgNuFaSK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E-qP8IZlDgd"
      },
      "source": [
        "## Image Math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_T1aSPddwwV"
      },
      "source": [
        "Here we will calculate the aspect of our DEM. The aspect is the orientation of the slope, measured clockwise in degrees from 0 to 360, where 0 is north-facing, 90 is east-facing, 180 is south-facing, and 270 is west-facing.\n",
        "\n",
        "For fun, and to demonstrate chaining methods together, we will also compute the sin of the aspect. The sin of the aspect (when using radians) represents the \"eastness\", with +1 being directly east and -1 being directly west."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvD6GgLbwC2O"
      },
      "outputs": [],
      "source": [
        "# Get the aspect (in degrees).\n",
        "aspect = ee.Terrain.aspect(dem)\n",
        "\n",
        "# Convert to radians, compute the sin of the aspect.\n",
        "sinImage = aspect.divide(180).multiply(math.pi).sin()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823IpGNP8J99"
      },
      "source": [
        "### Display maps side-by-side 🐍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmZO4txRPlyj"
      },
      "source": [
        "We can also display multiple maps in a cell output. Here we will display the DEM on the left and the sin of ths aspect of the DEM on the right. Here is how to (roughly) interpret the colors:\n",
        "\n",
        "| West  | North/South | East |\n",
        "| ----- | ----------- | ---- |\n",
        "| green | white       | blue |\n",
        "\n",
        "We picked Mount Shasta because of it's unique east/west facing mountain faces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDZln_ws8Nvo"
      },
      "outputs": [],
      "source": [
        "map_params_mount_shasta = {\n",
        "    'center': (41.40902, -122.19492),\n",
        "    'zoom':10\n",
        "}\n",
        "map2b = Map(**map_params_mount_shasta)\n",
        "map2b.addLayer(dem, {'min': 0, 'max': 4000}, 'elevation [meters]')\n",
        "map2c = Map(**map_params_mount_shasta)\n",
        "map2c.addLayer(\n",
        "    sinImage,\n",
        "    {'min': -1, 'max': 1,\n",
        "     'palette':['green', 'white', 'blue']},\n",
        "    'sine of aspect'\n",
        ")\n",
        "widgets.HBox([map2b, map2c])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VefKqIt5QTBW"
      },
      "source": [
        "The map objects have properties that can be queried (or set) from Python code. For example, the following code prints out the center coordinates (lon, lat) of the map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45XfgGi12lFd"
      },
      "outputs": [],
      "source": [
        "map2b.center"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjxHJ3TLrUHL"
      },
      "source": [
        "The properties of maps can be linked together, in order to sychronise the behavior. Run the following cell, then zoom and/or pan one of the maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_rCBh4XrQ3D"
      },
      "outputs": [],
      "source": [
        "def syncronize_maps(map_1, map_2):\n",
        "  map_center_link = widgets.link((map_1, 'center'), (map_2, 'center'))\n",
        "  map_zoom_link = widgets.link((map_1, 'zoom'), (map_2, 'zoom'))\n",
        "\n",
        "syncronize_maps(map2b, map2c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzeA0FDxvmTI"
      },
      "source": [
        "## Image statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDUSCTSYfkUO"
      },
      "source": [
        "We will explore image statistics by:\n",
        "\n",
        "1.   creating a map\n",
        "2.   creating a custom geometry by adding points on the map\n",
        "3.   calculating the stats of that custom geometry by calling `reduceRegion` on it.\n",
        "\n",
        "We will ultimately answer the question, \"what is the mean elevation?\" in the custom geometry that we defined.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhkfpFrDy6u4"
      },
      "source": [
        "### Draw Control: Create a Custom Geometry on a Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6-6no62vUJ8"
      },
      "source": [
        "In this section, we will create a custom geometry on the map using `ipyleflet.DrawControl` tool. If a geometry wasn't created using the tool, a default geometry is set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HUYOkJ4ltIo"
      },
      "outputs": [],
      "source": [
        "# Use ipyleaflet to add the ability to draw a geometry on our map.\n",
        "draw_control = ipyleaflet.DrawControl(\n",
        "    rectangle={},\n",
        "    polyline={},\n",
        "    circlemarker={},\n",
        ")\n",
        "def handle_draw(target, action, geo_json):\n",
        "    with output:\n",
        "      output.clear_output()\n",
        "      pprint(geo_json)\n",
        "draw_control.on_draw(handle_draw)\n",
        "\n",
        "map2d = Map(**map_init_params)\n",
        "output = widgets.Output(layout={'border': '1px solid black', 'width':\"200\"})\n",
        "map2d.addLayer(dem, {'min': 0, 'max': 1000}, 'elevation [meters]')\n",
        "map2d.add_control(draw_control)\n",
        "widgets.VBox([map2d, output])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ppnIZb-VbYP"
      },
      "source": [
        "The last geometry drawn on the map can be queries as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6ptvBkLVGKJ"
      },
      "outputs": [],
      "source": [
        "geom_clientside = draw_control.last_draw['geometry']\n",
        "geom_clientside"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CYsF3PuVM3_"
      },
      "source": [
        "It is possible that the preceding cell was run before any geometry was drawn on the map, so lets specify a default geometry in case that happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT7wI9Ew0fcM"
      },
      "outputs": [],
      "source": [
        "# If no geometry was drawn on a map, use a default geometry.\n",
        "if not geom_clientside:\n",
        "  geom_clientside = {'type': 'Polygon',\n",
        "    'coordinates': [[[-112.89, 36.46],\n",
        "                     [-113.08, 36.18],\n",
        "                     [-112.67, 36.16],\n",
        "                     [-112.89, 36.46]]]}\n",
        "\n",
        "  geom_clientside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buTzz0Xq2_ad"
      },
      "outputs": [],
      "source": [
        "# Create an Earth Engine server-side geometry\n",
        "geom = ee.Geometry(geom_clientside)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Ge9_zEUCJ2"
      },
      "source": [
        "### Spatial reduction: Calculate Stats for Our Custom Geometry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNe_-Lqbiv9i"
      },
      "source": [
        "We will use `reduceRegion` to calculate the mean elevation (in meters) for our custom geometry (that was created in the last section)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie5mfUJbvPIO"
      },
      "outputs": [],
      "source": [
        "# Compute the mean elevation in the polygon.\n",
        "meanDict = dem.reduceRegion(\n",
        "  reducer=ee.Reducer.mean(),\n",
        "  geometry=geom,\n",
        "  scale=90,\n",
        "  bestEffort=True\n",
        ")\n",
        "\n",
        "# Get the mean from the dictionary and print it.\n",
        "mean = meanDict.get('elevation')\n",
        "print('Mean elevation', mean.getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACOIndJ7-T3a"
      },
      "source": [
        "# Image Collections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmifi7Wth_rz"
      },
      "source": [
        "In this section we are going to use image collections to find the most cloudy and least cloudy images of Mountain View according to [Landsat 8](https://www.usgs.gov/landsat-missions/landsat-8-data-users-handbook) satelite imagery from 2016."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isdav8kpygVG"
      },
      "source": [
        "Specifically, we will use the [Landsat 8 Collection 2 Top of Atmosphere (TOA)](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_TOA) image collection. (TOA images have not been atmospherically corrected.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCq5JJc6vxAb"
      },
      "outputs": [],
      "source": [
        "landsat8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GtDNZnG-arZ"
      },
      "outputs": [],
      "source": [
        "# Create a geometry that is specified by the Geo for Good venue in Mountain View.\n",
        "point = ee.Geometry.Point(-122.0648754, 37.4225866)\n",
        "\n",
        "# Define a default visualization parameters for the Landsat image.\n",
        "landsat_rgb_viz = {\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'min': 0.0,\n",
        "    'max': 0.3,\n",
        "}\n",
        "\n",
        "# Filter by our Mountain View coordinates and by the year 2016, which was\n",
        "# arbitrarily chosen.\n",
        "spatialFiltered = landsat8.filterBounds(point)\n",
        "temporalFiltered = spatialFiltered.filterDate('2016-01-01', '2016-12-31')\n",
        "\n",
        "# Sort based on the amount of cloud cover.\n",
        "least_cloudy_image = temporalFiltered.sort('CLOUD_COVER').first()\n",
        "most_cloudy_image = temporalFiltered.sort('CLOUD_COVER', opt_ascending=False).first()\n",
        "\n",
        "map_most_cloudy = Map(**map_init_params)\n",
        "map_least_cloudy = Map()\n",
        "map_most_cloudy.addLayer(most_cloudy_image, landsat_rgb_viz)\n",
        "map_least_cloudy.addLayer(least_cloudy_image, landsat_rgb_viz)\n",
        "syncronize_maps(map_most_cloudy, map_least_cloudy)\n",
        "\n",
        "widgets.VBox([\n",
        "    widgets.Label(f\"CLOUD_COVER (most) = {most_cloudy_image.getInfo()['properties']['CLOUD_COVER']}\"),\n",
        "    map_most_cloudy,\n",
        "    widgets.Label(f\"CLOUD_COVER (least) = {least_cloudy_image.getInfo()['properties']['CLOUD_COVER']}\"),\n",
        "    map_least_cloudy\n",
        "],\n",
        "layout=widgets.Layout(max_height=\"600px\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ej-r9IApJ0m"
      },
      "source": [
        "## Compositing and Mosaicking\n",
        "\n",
        "Compositing, masking and mosaicking are different technqiues that we use to process image collections.\n",
        "\n",
        "**Compositing** refers to the process of aggregating individual pixel values in a collection. The median is often used in composites to remove the effects of cloud cover (bright pixels) and shadows (dark pixels).\n",
        "\n",
        "In **mosaics**, individual images are stitched together (side by side). Often it is the images that were most recent that are stitched together. We will be using the Landsat 8 dataset. You can understand why the mosaic looks the way it does by taking a look at the [Landsat orbit](https://www.youtube.com/watch?v=yPF2jpjB3Qw).\n",
        "\n",
        "We will first calculate the composite and the mosaic for Lansat 8 data for the year 2016 (year is arbitrarily chosen) for the point centered around the Geo for Good venue in Mountain View:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XURS3z0TAmka"
      },
      "outputs": [],
      "source": [
        "# Filter by the year 2016 (arbitrarily chosen).\n",
        "temporalFiltered = landsat8.filterDate('2016-01-01', '2016-12-31')\n",
        "# Calculate the mosaic.\n",
        "mosaic = temporalFiltered.mosaic()\n",
        "# Calculate the composite by getting the median over time, for each band, in\n",
        "# each pixel.\n",
        "median = temporalFiltered.median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPx6of6zxzMV"
      },
      "source": [
        "We will display the mosaic on the right and the composite on the left:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt96jUp_yY6n"
      },
      "outputs": [],
      "source": [
        "# Compare the mosaic and composite results.\n",
        "map4a = Map(**map_init_params)\n",
        "map4a.addLayer(mosaic, landsat_rgb_viz, 'Landsat 8 (mosaic)')\n",
        "map4b = Map(**map_init_params)\n",
        "map4b.addLayer(median, landsat_rgb_viz, 'Landsat 8 (median)')\n",
        "syncronize_maps(map4a, map4b)\n",
        "widgets.HBox([map4a, map4b])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WiWNiAA7B96"
      },
      "source": [
        "Why does the mosaic have white lines?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebgiNG5069Zz"
      },
      "outputs": [],
      "source": [
        "HTML(\n",
        "  '<iframe width=\"640\" height=\"385\" '\n",
        "  'src=\"https://www.youtube.com/embed/yPF2jpjB3Qw\" '\n",
        "  'frameborder=\"0\"></iframe>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tWCMVsgGBhV"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQkzZ9A3q2pJ"
      },
      "source": [
        "Masking pixels in an image makes those pixels transparent and excludes them from analysis. Pixels with a mask values of 0 or below will be transparent, mask values between 0 and 1 will be partially rendered, whereas mask values above 1 will be fully rendered.\n",
        "\n",
        "In this example we will use a mask to only look at land data (exclude the water data) of the [Hansen Global Forest Change](https://developers.google.com/earth-engine/datasets/catalog/UMD_hansen_global_forest_change_2021_v1_9) dataset. This dataset is used because in the `datamask` column, water has a value of 2, land has the value 1, and 'no data' has the value 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PX-DdczFQT9"
      },
      "outputs": [],
      "source": [
        "# Load or import the Hansen et al. forest change dataset.\n",
        "hansenImage = ee.Image('UMD/hansen/global_forest_change_2021_v1_9')\n",
        "\n",
        "# Select the land/water mask.\n",
        "datamask = hansenImage.select('datamask')\n",
        "\n",
        "# Create a binary mask. This means we are only selecting the land pixels (based\n",
        "# on how the datamask column is defined in the dataset).\n",
        "mask = datamask.eq(1)\n",
        "\n",
        "# Update the composite mask with the water mask.\n",
        "maskedComposite = median.updateMask(mask)\n",
        "\n",
        "map4c = Map(**map_init_params)\n",
        "map4c.addLayer(maskedComposite, landsat_rgb_viz, 'masked')\n",
        "map4c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwJdjBjENI8S"
      },
      "source": [
        "# NDVI, Mapping a Function over a Collection, Quality Mosaicking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA9Vami5z9xq"
      },
      "source": [
        "In this section we will calculate the Normalized Difference Vegetation Index (NDVI) for Landsat 8 images.\n",
        "\n",
        "The NDVI is used to determine how much green vegetation exists in an area. NDVI relies on green vegetation having a strong reflectance for Near Infrared (NIR) and a weak reflectance for red light.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE9RYKaHoijm"
      },
      "source": [
        "The formula for NDVI is as follows:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{NDVI} = \\frac{\\text{NIR}-\\text{R}}{\\text{NIR}+\\text{R}}\n",
        "\\end{align}\n",
        "\n",
        "where $\\text{NIR}$ and $\\text{R}$ are the spectral reflectance in the near-infrared and red (visible) regions, respectively (source: [wikipedia](https://en.wikipedia.org/wiki/Normalized_difference_vegetation_index)).\n",
        "\n",
        "For Landsat 8 and 9:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{NDVI} = \\frac{\\text{Band5}-\\text{Band4}}{\\text{Band5}+\\text{Band4}}\n",
        "\\end{align}\n",
        "\n",
        "where $\\text{Band5}$ and $\\text{Band4}$ are the corresponding Landsat bands, respectively (source: [USGS](https://www.usgs.gov/landsat-missions/landsat-normalized-difference-vegetation-index#:~:text=In%20Landsat%204%2D7%2C%20NDVI,Band%205%20%2B%20Band%204)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXg2xAvqvifs"
      },
      "source": [
        "Below are examples of NDVI calculated for two pieces of vegetation in different states.\n",
        "\n",
        "![NDVI](https://earthobservatory.nasa.gov/ContentFeature/MeasuringVegetation/Images/ndvi_example.jpg)\n",
        "\n",
        "*Image source: [earthobservatory.nasa.gov](https://earthobservatory.nasa.gov/ContentFeature/MeasuringVegetation/Images/ndvi_example.jpg)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xh7SuTG3oWX"
      },
      "source": [
        "### Calculate NDVI on a Single Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z296JNYp3dpS"
      },
      "source": [
        "First we will calculate the NDVI on a single image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBdqGdkrKTiD"
      },
      "outputs": [],
      "source": [
        "# Define a point of interest.\n",
        "point = ee.Geometry.Point(location_lonlat)\n",
        "\n",
        "# Get the least cloudy image in 2016.\n",
        "image = ee.Image(\n",
        "  landsat8.filterBounds(point)\n",
        "          .filterDate('2016-01-01', '2016-12-31')\n",
        "          .sort('CLOUD_COVER')\n",
        "          .first()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kofuuV4wuRi-"
      },
      "source": [
        "NDVI can be calculated within Earth Engine as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvxKEaR9O06C"
      },
      "outputs": [],
      "source": [
        "nir = image.select('B5')\n",
        "red = image.select('B4')\n",
        "ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T73zk-GEuix0"
      },
      "source": [
        "Let's display a map showing the `ndvi` object. We will use simple visualization  where blue is low (negative) NDVI and green is high (positive) NDVI. Water tends to result in a negative NDVI value, while clouds have NDVI values near zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAIP7DnyNb3_"
      },
      "outputs": [],
      "source": [
        "ndvi_vis_arams = {\n",
        "    'bands': 'NDVI',\n",
        "    'min': -1,\n",
        "    'max': 1,\n",
        "    'palette': ['blue', 'white', 'green']\n",
        "}\n",
        "\n",
        "map5a = Map(**map_init_params)\n",
        "map5a.addLayer(ndvi, ndvi_vis_arams, 'NDVI image')\n",
        "map5a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiF8Kyc97Z39"
      },
      "source": [
        "Because calculating band ratios (such as NDVI) is commonly done as part of a remote sensing analysis workflow, Earth Engine images have a shortcut method to make this easier: `ee.Image.normalizedDifference()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iHbLw2nPWyr"
      },
      "outputs": [],
      "source": [
        "# Remove the NDVI layer\n",
        "map5a.remove_layer(map5a.layers[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3wOypQzOiAW"
      },
      "outputs": [],
      "source": [
        "# Redefine NDVI using ee.Image.normalizedDifference, and add it back again.\n",
        "ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI')\n",
        "map5a.addLayer(ndvi, ndvi_vis_arams, 'NDVI image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk9KTmJJ8D9p"
      },
      "source": [
        "## Applying NDVI to an Image Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9pIcInFoDg1"
      },
      "source": [
        "In Earth Engine we can apply an algorithm that works on a single image (such as calculating NDVI) to all images in a collection. To do this, we first define a Python function that that operates on a single image. In this specfic example, the function takes an image, calculates NDVI, appends it to the image, and then returns the new image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Izzr47-DP9Ye"
      },
      "outputs": [],
      "source": [
        "def add_ndvi(image):\n",
        "  ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI')\n",
        "  return image.addBands(ndvi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIf_2AUu8nHj"
      },
      "source": [
        "To test it out, we can apply the `add_ndvi` function to a single image. *(This is a very useful pattern for testing and debugging functions that you write)*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HmYx75C8nh6"
      },
      "outputs": [],
      "source": [
        "ndvi = add_ndvi(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K691ZDpCMOFa"
      },
      "source": [
        "We can add this NDVI image to a map/inspector panel, and then use the inspector to confirm that the NDVI band was added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF1x4w2HDh1x"
      },
      "outputs": [],
      "source": [
        "map_panel_5 = MapWithInspector(**map_init_params)\n",
        "map_panel_5.map.addLayer(ndvi, ndvi_vis_arams, 'NDVI')\n",
        "map_panel_5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZuCnQM68b8J"
      },
      "source": [
        "But it is even more useful to \"map\" (i.e. apply) the function over all the images in an image collection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9HaSYH08YxW"
      },
      "outputs": [],
      "source": [
        "with_ndvi = landsat8.map(add_ndvi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udenzq4qNUnk"
      },
      "source": [
        "We can then mosaic the images together, and display it. Note that many images processed by the `add_ndvi` function are visible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyx8qq1YMfTk"
      },
      "outputs": [],
      "source": [
        "map5b = Map(**map_init_params)\n",
        "map5b.addLayer(with_ndvi.mosaic(), ndvi_vis_arams, 'NDVI mosaic')\n",
        "map5b.zoom = 8  # zoom out a bit from the default\n",
        "map5b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkkJXjewNEez"
      },
      "source": [
        "Note that the result is pretty noisy, because `.mosaic()` preferentialy selects the latest pixels in the collection (which often may have clouds). We will improve upon this in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsNJu3QrEzLa"
      },
      "source": [
        "## Make a greenest pixel composite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVks7JhW4Td8"
      },
      "source": [
        "In this section we will use [`qualityMosaic`](https://developers.google.com/earth-engine/apidocs/ee-imagecollection-qualitymosaic) to get less noisy NDVI data. `qualityMosaic` works by taking the maximum value composite for the band you provide. In our example, this means choosing the pixel with the largest NDVI value. The maximum is taken to avoid areas with clouds, which have very low NDVI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sadNR0nkD7-o"
      },
      "outputs": [],
      "source": [
        "greenest = with_ndvi.qualityMosaic('NDVI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsX9EkhUPfdj"
      },
      "outputs": [],
      "source": [
        "map5c = Map(**map_init_params)\n",
        "map5c.addLayer(greenest, landsat_rgb_viz, 'greenest pixel mosaic')\n",
        "map5c.zoom = 8  # zoom out a bit from the default\n",
        "map5c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cthndqoQVjf"
      },
      "source": [
        "# Exporting Charts and Images\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqIu33YGQbwn"
      },
      "source": [
        "## Charting 🐍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hC35DwK8DeO"
      },
      "source": [
        "Python has many plotting options, for example: matplotlib, bokeh, altair, plotly, etc. You can refer to [The Python Visualization Landscape](https://www.youtube.com/watch?v=FytuB8nFHPQ) talk from PyCon 2017 for more information on the plotting libraries that Python offers.\n",
        "\n",
        "The goal of this section is to create a timeseries plot using Altair to showcase one Python plotting library.\n",
        "\n",
        "We will create a timeseries plot of NDVI for the Geo for Good venue in Mountain View."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FywVeUsNWLrs"
      },
      "outputs": [],
      "source": [
        "stat_region = ee.Geometry.Point(location_lonlat)\n",
        "stat_region.getInfo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoOJzSex-Fxw"
      },
      "source": [
        "Filter the NDVI image collection to only get images that occur in the Geo for Good venue in Mountain View:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIn6qKSXUS3h"
      },
      "outputs": [],
      "source": [
        "filtered = with_ndvi.filterBounds(stat_region)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Ed3leS-f91"
      },
      "source": [
        "Create a function that takes the image and creates an `ee.Feature` with the mean and the image timestamp (to help enable timeseries plotting):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV8HbweuRLnB"
      },
      "outputs": [],
      "source": [
        "def reduce_region_function(img):\n",
        "  \"\"\"Return a feature containing the mean value of a region and a timestamp.\"\"\"\n",
        "\n",
        "  stat = img.reduceRegion(\n",
        "      reducer=ee.Reducer.mean(),\n",
        "      geometry=stat_region,\n",
        "      scale=30\n",
        "  )\n",
        "  return ee.Feature(stat_region, stat).set({'millis': img.date().millis()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM-oZ_45_BF2"
      },
      "source": [
        "The next two code blocks are helper functions that are used to get the feature properties into a dictionary and then the dictionary values into a pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi7geadA7a9M"
      },
      "outputs": [],
      "source": [
        "# Define a function to transfer feature properties to a dictionary.\n",
        "def fc_to_dict(fc):\n",
        "  prop_names = fc.first().propertyNames()\n",
        "  prop_lists = fc.reduceColumns(\n",
        "      reducer=ee.Reducer.toList().repeat(prop_names.size()),\n",
        "      selectors=prop_names).get('list')\n",
        "\n",
        "  return ee.Dictionary.fromLists(prop_names, prop_lists)\n",
        "\n",
        "def fc_to_dataframe(fc):\n",
        "  \"\"\"Converts a feature collection to a Pandas dataframe.\"\"\"\n",
        "  return pd.DataFrame(fc_to_dict(fc).getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdxgob7A_M4b"
      },
      "source": [
        ":Here we apply the helper functions defined above to create a Pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ1k9-qHQnM3"
      },
      "outputs": [],
      "source": [
        "stat_fc = (\n",
        "  ee.FeatureCollection(\n",
        "    filtered.map(reduce_region_function)\n",
        "  ).filter(\n",
        "    ee.Filter.notNull(filtered.first().bandNames())\n",
        "  )\n",
        ")\n",
        "df = fc_to_dataframe(stat_fc)\n",
        "df['timestamp'] = pd.to_datetime(df['millis'], unit='ms')\n",
        "#df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvx7blMr_Um2"
      },
      "source": [
        "Next we narrow our scope of the feature collection to only focus on the bands that matter for NDVI, the `B5` (near-infrared), `B4` (red) and `NDVI` bands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBlOGpBw3fcb"
      },
      "outputs": [],
      "source": [
        "keys = ['B5', 'B4', 'NDVI']\n",
        "source = pd.melt(\n",
        "    df[['B5', 'B4', 'NDVI', 'timestamp']],\n",
        "    id_vars='timestamp',\n",
        "    value_vars=keys,\n",
        "    var_name='band'\n",
        ")\n",
        "source.head()  # display the first few values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UPngbuW_mUU"
      },
      "source": [
        "Here we use the dataframe to plot the timeseries for B5, B4, and NDVI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeKYcEQl3qh9"
      },
      "outputs": [],
      "source": [
        "alt.Chart(source).mark_line().encode(\n",
        "    x='timestamp:T',\n",
        "    y='value',\n",
        "    color=alt.Color(\n",
        "        'band',\n",
        "        scale=alt.Scale(\n",
        "            domain=['B4', 'B5', 'NDVI'],\n",
        "            range=['red', 'purple', 'green']\n",
        "        )\n",
        "    ),\n",
        "    tooltip=['band', 'value', 'timestamp:T']\n",
        ").interactive(bind_y=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkgclKMOit8S"
      },
      "source": [
        "## Exporting Images 🐍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVvqIRQHSb4b"
      },
      "source": [
        "This section will demonstrat how to export an image, using the Python client library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbkwB9zySiQ4"
      },
      "source": [
        "To start, create a 3-band, 8-bit, color-IR composite that we will export."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGq1erzliJdB"
      },
      "outputs": [],
      "source": [
        "visualization = greenest.visualize(**landsat_rgb_viz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZt-ufJtHrug"
      },
      "source": [
        "We can preview the visualization by adding it to an interative map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqRbjN3rlMtj"
      },
      "outputs": [],
      "source": [
        "map_init_params_eastern_sierra = {\n",
        "    'center': (37.05, -118.40),\n",
        "    'zoom':8\n",
        "}\n",
        "map6a = Map(**map_init_params_eastern_sierra)\n",
        "map6a.addLayer(visualization, {}, 'visualization test')\n",
        "map6a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7e2DHhfSruB"
      },
      "source": [
        "Next we can create a *task* that can be used to export the image. Note that a task will not run until it is *started*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0vhmjTKlHii"
      },
      "outputs": [],
      "source": [
        "asset_id = 'projects/ee-ee-test-te/assets/temp/g4g22_python_export_example'\n",
        "\n",
        "task = ee.batch.Export.image.toAsset(\n",
        "      visualization,\n",
        "      description='Greenest_pixel_composite',\n",
        "      assetId=asset_id,\n",
        "      scale=30,\n",
        "      region=\"\"\"[[[-119.2, 37.9],\n",
        "                  [-119.2, 36.2],\n",
        "                  [-117.6, 36.2],\n",
        "                  [-117.6, 37.9]]]\"\"\"  # California, East Side of Sierras\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RydLfFZBTRTo"
      },
      "source": [
        "The task can take ~10 minutes to finish. For this training, we already ran the task, so the `start()` call has been commented out. However, if you have updated the analysis and want to export a new image, you can uncomment the following line and run it (after first updating the `asset_id` in the previous cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3I2UQrzTPWf"
      },
      "outputs": [],
      "source": [
        "# task.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSoo6256lzTM"
      },
      "source": [
        "You can check on the status of your task by visitng the Earth Engine task manager webpage: https://code.earthengine.google.com/tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-6kCjw__il2"
      },
      "outputs": [],
      "source": [
        "exported_asset = ee.Image(asset_id)\n",
        "\n",
        "map6b = Map(**map_init_params_eastern_sierra)\n",
        "map6b.addLayer(exported_asset, {}, 'exported asset')\n",
        "map6b"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}