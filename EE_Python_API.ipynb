{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jerry086/CS6140CarbonMapping/blob/main/EE_Python_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUpzfef3quYi"
      },
      "source": [
        "# Forest Carbon Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-hK3sO_XwcR"
      },
      "source": [
        "## Setting Up Enviornment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive to the Colab VM"
      ],
      "metadata": {
        "id": "5S4XfKAzbBEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive if dataset is saved in it\n",
        "# skip the code if dataset is uploaded or downloaded from google cloud\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EcsqT7R8JNP",
        "outputId": "0ce9d756-ea62-43cc-f797-c12a15b83698"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate google cloud account"
      ],
      "metadata": {
        "id": "oECLbVFhcGuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# authenticate google cloud if dataset is saved in it\n",
        "# TODO: deploy T4 GPU on google cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "KacxsOvxcMMF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDunjJcBZGFB"
      },
      "source": [
        "Authenticate and authorize access to Earth Engine."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import, authenticate and initialize the Earth Engine library.\n",
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWK3h38Mcnn7",
        "outputId": "f7b4cad2-6596-4a85-9df6-a3b4c95a7126"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=q0kEHCOaOUZwAhb8Ew239nKELbJtO6UsH90O0zluD6o&tc=KbSTS7-4Y2RGQrkfC6w1RHtI8nxHgsExnTWxtlR0Gmc&cc=PXVfseTv19yM3OA9CthGfhv8eaaz3FQLI3D_HFezwrc\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below.\n",
            "Enter verification code: 4/1AZEOvhWDgDaHNHXEf5Ys_I57BOs3ssR0KMiGKnb30YC2tBDBJLhAAOHmITA\n",
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFMJrbt8rZ9z"
      },
      "source": [
        "## Install & import Python packages\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoUgp_unsCfZ"
      },
      "source": [
        "Import Python packages used throughout this notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Folium setup.\n",
        "import folium\n",
        "print(folium.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYZur_13fU6N",
        "outputId": "312ed94a-2527-4039-d9ea-23eb6065d003"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow setup.\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLPIT3XaqhkY",
        "outputId": "32d623f6-8b4e-40d2-c4ff-d041ec8b2c35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set global variables"
      ],
      "metadata": {
        "id": "qEqG89idJjVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify names locations for outputs in Google Drive.\n",
        "# Uncomment the code for Google Drive storage.\n",
        "# FOLDER = 'carbon_mapping'\n",
        "\n",
        "# Specify names locations for outputs in Google Cloud.\n",
        "BUCKET = 'cs6140'\n",
        "FOLDER = 'dataset'\n",
        "TRAINING_BASE = 'training_patches'\n",
        "EVAL_BASE = 'eval_patches'\n",
        "\n",
        "# Specify feature bands to the model and the response variable.\n",
        "# TODO: explore more bands\n",
        "BANDS = ['NDVI', 'EVI']\n",
        "RESPONSE = 'annualNPP'\n",
        "FEATURES = BANDS + [RESPONSE]\n",
        "\n",
        "# Specify the size and shape of patches (256x256 pixels images) expected by the model.\n",
        "KERNEL_SIZE = 256\n",
        "KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]\n",
        "\n",
        "# Columns for input features and response\n",
        "COLUMNS = [\n",
        "  # Configuration for parsing a fixed-length input feature.\n",
        "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
        "]\n",
        "# Label each column with feature name by dictionary\n",
        "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
        "\n",
        "# Sizes of the training and evaluation datasets.\n",
        "# TODO: modify as needed\n",
        "TRAIN_SIZE = 16000\n",
        "EVAL_SIZE = 8000\n",
        "\n",
        "# Specify model training parameters.\n",
        "# TODO: modify as needed\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "BUFFER_SIZE = 2000\n",
        "OPTIMIZER = 'Adam'\n",
        "LOSS = 'MeanSquaredError'\n",
        "METRICS = ['RootMeanSquaredError']"
      ],
      "metadata": {
        "id": "u-lC2KAKJk6h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afVIId1ysLYe"
      },
      "source": [
        "# Visualizing Images and Image Bands"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This research focuses on Forest Carbon Mapping in North America area"
      ],
      "metadata": {
        "id": "CTK7p43wnNQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the region of interest (ROI)\n",
        "north_america_polygon = ee.Geometry.Polygon([\n",
        "    [-168, 65],  # Northwest corner (top-left)\n",
        "    [-168, 10],  # Southwest corner (bottom-left)\n",
        "    [-52, 10],   # Southeast corner (bottom-right)\n",
        "    [-52, 65],   # Northeast corner (top-right)\n",
        "])"
      ],
      "metadata": {
        "id": "OgBgHP0mnJkD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NDVI and EVI bands from [MOD13Q1.061 Terra Vegetation Indices 16-Day Global 250m](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD13Q1#bands)."
      ],
      "metadata": {
        "id": "X0D4ebnIm5JZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kese6umry9Rp"
      },
      "outputs": [],
      "source": [
        "# Load the MODIS Vegetation Indices (MOD13Q1) collection\n",
        "modis_collection = ee.ImageCollection('MODIS/061/MOD13Q1')\n",
        "\n",
        "# Filter the collection based on the ROI and time range\n",
        "modis_filtered = modis_collection.filterDate('2018-01-01', '2018-12-31')\n",
        "modis_image = modis_filtered.mean()\n",
        "# .clip(north_america_polygon)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use folium to visualize the image\n",
        "mapid = modis_image.getMapId({'bands': ['NDVI'], 'min': 0, 'max': 8000, 'palette': [\n",
        "    'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',\n",
        "    '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',\n",
        "    '012e01', '011d01', '011301'\n",
        "  ]})\n",
        "# Center in Vancouver\n",
        "map = folium.Map(location=[49.2827, -123.1207])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='NDVI',\n",
        "  ).add_to(map)\n",
        "\n",
        "mapid = modis_image.getMapId({'bands': ['EVI'], 'min': 0, 'max': 5000, 'palette': [\n",
        "    'ffffff', 'ce7e45', 'df923d', 'f1b555', 'fcd163', '99b718', '74a901',\n",
        "    '66a000', '529400', '3e8601', '207401', '056201', '004c00', '023b01',\n",
        "    '012e01', '011d01', '011301'\n",
        "  ]})\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='EVI',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "yXH0v0pHfX5q",
        "outputId": "91adf08e-c149-48ab-99f0-b910d150f92f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7d94500d11b0>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_8fcd14c237f439ec927480253374dfc6 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_8fcd14c237f439ec927480253374dfc6&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_8fcd14c237f439ec927480253374dfc6 = L.map(\n",
              "                &quot;map_8fcd14c237f439ec927480253374dfc6&quot;,\n",
              "                {\n",
              "                    center: [49.2827, -123.1207],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_21977a012e4b1241379098b8720f7a06 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_8fcd14c237f439ec927480253374dfc6);\n",
              "        \n",
              "    \n",
              "            var tile_layer_4bf27c1cdc785ee6ed477a0bc0d9112a = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/5160767856382d0863e02280f437b35b-05bb09478d87f15fc410acbce5b439be/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_8fcd14c237f439ec927480253374dfc6);\n",
              "        \n",
              "    \n",
              "            var tile_layer_89bf2779417bf1495b48f62ac86bb524 = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/6d1f054dc7ca1c7218367c1a879751f0-cc8ea1d75747f813cb827da6d912d99f/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_8fcd14c237f439ec927480253374dfc6);\n",
              "        \n",
              "    \n",
              "            var layer_control_9554fa241e6b6af5689f7d40e7ebf4d4 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_21977a012e4b1241379098b8720f7a06,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;NDVI&quot; : tile_layer_4bf27c1cdc785ee6ed477a0bc0d9112a,\n",
              "                    &quot;EVI&quot; : tile_layer_89bf2779417bf1495b48f62ac86bb524,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_9554fa241e6b6af5689f7d40e7ebf4d4.base_layers,\n",
              "                layer_control_9554fa241e6b6af5689f7d40e7ebf4d4.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_8fcd14c237f439ec927480253374dfc6);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Response: the amount of carbon captured by plants in an ecosystem, after accounting for losses due to respiration, from [MODIS Net Primary Production CONUS](https://developers.google.com/earth-engine/datasets/catalog/UMT_NTSG_v2_MODIS_NPP#bands)."
      ],
      "metadata": {
        "id": "d0n3qOnpgu7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "npp_collection = ee.ImageCollection('UMT/NTSG/v2/MODIS/NPP')\n",
        "npp_filtered = npp_collection.filterDate('2018-01-01', '2018-12-31')\n",
        "npp_image = npp_filtered.mean().select('annualNPP')\n",
        "\n",
        "# normalize npp image to [0, 1]\n",
        "stats = npp_image.reduceRegion(\n",
        "    reducer=ee.Reducer.minMax(),\n",
        "    geometry=north_america_polygon,\n",
        "    scale=250,\n",
        "    bestEffort=True\n",
        ").getInfo()\n",
        "print(stats)\n",
        "min, max = stats['annualNPP_min'], stats['annualNPP_max']\n",
        "npp_normalized = npp_image.unitScale(min, max)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVq4oOzMgwd4",
        "outputId": "c6f80037-caa7-49c2-d080-df8d691aeb39"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'annualNPP_max': 29278, 'annualNPP_min': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect some points for validation\n",
        "points = [\n",
        "    ee.Geometry.Point(-115.16, 35.49),\n",
        "    ee.Geometry.Point(-90.54, 38.7)\n",
        "]\n",
        "\n",
        "# Function to extract pixel values at specified points\n",
        "def get_pixel_values(point):\n",
        "    value_dict = npp_normalized.reduceRegion(reducer=ee.Reducer.first(), geometry=point, scale=250,bestEffort=True)\n",
        "    return value_dict\n",
        "\n",
        "# Loop through the points and get the pixel values\n",
        "for point in points:\n",
        "    pixel_values = get_pixel_values(point)\n",
        "    print(pixel_values.getInfo())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HijqI9JX8kOx",
        "outputId": "8224a99c-f918-40c6-e2a5-1e3b916ec090"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'annualNPP': 0.030910581323860917}\n",
            "{'annualNPP': 0.44173099255413617}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapid = npp_image.getMapId({'min': 0, 'max': 1, 'palette': ['bbe029', '0a9501', '074b03']})\n",
        "map = folium.Map(location=[38., -122.5])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='npp',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "DcQ2WCJC8s3H",
        "outputId": "70bb0d8e-6eb8-4e18-c45e-63023a46c51a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7d944de0b220>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_02297413019c6f246a37dcb1571e708e {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_02297413019c6f246a37dcb1571e708e&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_02297413019c6f246a37dcb1571e708e = L.map(\n",
              "                &quot;map_02297413019c6f246a37dcb1571e708e&quot;,\n",
              "                {\n",
              "                    center: [38.0, -122.5],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 10,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_a3c339a60d4f6631094530aec2940383 = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_02297413019c6f246a37dcb1571e708e);\n",
              "        \n",
              "    \n",
              "            var tile_layer_073bbd8802325208f5b92d86df72cecb = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/57d8dc70efd306ddd596d08a9c029344-1515dae59c2282672e3b0ca2b542f836/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_02297413019c6f246a37dcb1571e708e);\n",
              "        \n",
              "    \n",
              "            var layer_control_dec99a132ebb2f3bdbb53daba2fa0d47 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_a3c339a60d4f6631094530aec2940383,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;npp&quot; : tile_layer_073bbd8802325208f5b92d86df72cecb,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_dec99a132ebb2f3bdbb53daba2fa0d47.base_layers,\n",
              "                layer_control_dec99a132ebb2f3bdbb53daba2fa0d47.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_02297413019c6f246a37dcb1571e708e);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stack the 2D images (Terra Vegetation Indices and MODIS Net Primary Production) to create a single image from which samples can be taken. Convert the image into an array image in which each pixel stores 256x256 patches of pixels for each band. To export training patches, convert a multi-band image to an array image using neighborhoodToArray(), then sample the image at points.\n"
      ],
      "metadata": {
        "id": "QOOIb0hjphjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "featureStack = ee.Image.cat([\n",
        "  modis_image.select(BANDS),\n",
        "  # add more input datasets here\n",
        "  npp_normalized.select(RESPONSE)\n",
        "]).float()\n",
        "# 1d 256 [1, ..., 1]\n",
        "list = ee.List.repeat(1, KERNEL_SIZE)\n",
        "# 2d 256x256\n",
        "lists = ee.List.repeat(list, KERNEL_SIZE)\n",
        "kernel = ee.Kernel.fixed(KERNEL_SIZE, KERNEL_SIZE, lists)\n",
        "\n",
        "arrays = featureStack.neighborhoodToArray(kernel)"
      ],
      "metadata": {
        "id": "g36a-LDIpwgP"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use some pre-made geometries to sample the stack in strategic locations. Specifically, these are hand-made polygons in which to take the 256x256 samples. Display the sampling polygons on a map, red for training polygons, blue for evaluation."
      ],
      "metadata": {
        "id": "Imo_xf43sfzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: personalize polygons\n",
        "trainingPolys = ee.FeatureCollection('projects/google/DemoTrainingGeometries')\n",
        "evalPolys = ee.FeatureCollection('projects/google/DemoEvalGeometries')\n",
        "\n",
        "polyImage = ee.Image(0).byte().paint(trainingPolys, 1).paint(evalPolys, 2)\n",
        "polyImage = polyImage.updateMask(polyImage)\n",
        "\n",
        "mapid = polyImage.getMapId({'min': 1, 'max': 2, 'palette': ['red', 'blue']})\n",
        "map = folium.Map(location=[38., -100.], zoom_start=5)\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='training polygons',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "z7FA6g2aseu0",
        "outputId": "777cd34f-db12-47ff-85c3-fc48db05d835"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7d944de0b130>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_9fc004bdfde4175574bc057fb0ed67e7 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_9fc004bdfde4175574bc057fb0ed67e7&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_9fc004bdfde4175574bc057fb0ed67e7 = L.map(\n",
              "                &quot;map_9fc004bdfde4175574bc057fb0ed67e7&quot;,\n",
              "                {\n",
              "                    center: [38.0, -100.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    zoom: 5,\n",
              "                    zoomControl: true,\n",
              "                    preferCanvas: false,\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_dba3ef9b1e1cd1e6c123c8d63e6844dc = L.tileLayer(\n",
              "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca target=\\&quot;_blank\\&quot; href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_9fc004bdfde4175574bc057fb0ed67e7);\n",
              "        \n",
              "    \n",
              "            var tile_layer_a4b384e5b856e9711f054100dba93d6c = L.tileLayer(\n",
              "                &quot;https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/3959de45a944ccc4fa1fadd758c8f8c9-db6a0017dd75bfc028d4b9fce742143a/tiles/{z}/{x}/{y}&quot;,\n",
              "                {&quot;attribution&quot;: &quot;Map Data \\u0026copy; \\u003ca href=\\&quot;https://earthengine.google.com/\\&quot;\\u003eGoogle Earth Engine\\u003c/a\\u003e&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
              "            ).addTo(map_9fc004bdfde4175574bc057fb0ed67e7);\n",
              "        \n",
              "    \n",
              "            var layer_control_4fc68d6392942c9457e75989fb96a1f4 = {\n",
              "                base_layers : {\n",
              "                    &quot;openstreetmap&quot; : tile_layer_dba3ef9b1e1cd1e6c123c8d63e6844dc,\n",
              "                },\n",
              "                overlays :  {\n",
              "                    &quot;training polygons&quot; : tile_layer_a4b384e5b856e9711f054100dba93d6c,\n",
              "                },\n",
              "            };\n",
              "            L.control.layers(\n",
              "                layer_control_4fc68d6392942c9457e75989fb96a1f4.base_layers,\n",
              "                layer_control_4fc68d6392942c9457e75989fb96a1f4.overlays,\n",
              "                {&quot;autoZIndex&quot;: true, &quot;collapsed&quot;: true, &quot;position&quot;: &quot;topright&quot;}\n",
              "            ).addTo(map_9fc004bdfde4175574bc057fb0ed67e7);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV890gPHeZqz"
      },
      "source": [
        "# Sampling\n",
        "\n",
        "Take a sample from each polygon and merge the results into a single export.  The key step is sampling the array image at points, to get all the pixels in a 256x256 neighborhood at each point. Export a single TFRecord file that contains patches of pixel values in each record to build the training and testing data for the FCNN. Since each record potentially contains a lot of data (especially with big patches or many input bands), some manual sharding of the computation is necessary to avoid the `computed value too large` error.  Specifically, the following code takes multiple (smaller) samples within each geometry, merging the results to get a single export."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyRpvwENxE-A",
        "cellView": "both"
      },
      "source": [
        "# Convert the feature collections to lists for iteration.\n",
        "trainingPolysList = trainingPolys.toList(trainingPolys.size())\n",
        "evalPolysList = evalPolys.toList(evalPolys.size())\n",
        "\n",
        "# These numbers determined experimentally.\n",
        "n = 200 # Number of shards in each polygon, reduced to 200 samples\n",
        "N = 2000 # Total sample size in each polygon.\n",
        "\n",
        "# Export all the training data (in many pieces), with one task\n",
        "# per geometry.\n",
        "for g in range(trainingPolys.size().getInfo()):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "  # randomly choose one sample in each iteration\n",
        "  for i in range(n):\n",
        "    sample = arrays.sample(\n",
        "      region = ee.Feature(trainingPolysList.get(g)).geometry(),\n",
        "      scale = 250,\n",
        "      numPixels = N / n, # Size of the shard.\n",
        "      seed = i,\n",
        "      tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "\n",
        "  desc = 'training_patches' + '_g' + str(g)\n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = geomSample,\n",
        "    description = desc,\n",
        "    # for Google Cloud Export\n",
        "    bucket = BUCKET,\n",
        "    fileNamePrefix = FOLDER + '/' + desc,\n",
        "    # for Google Drive Export\n",
        "    # folder = FOLDER,\n",
        "    # fileNamePrefix = desc,\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "# Export all the evaluation data.\n",
        "for g in range(evalPolys.size().getInfo()):\n",
        "  geomSample = ee.FeatureCollection([])\n",
        "  for i in range(n):\n",
        "    sample = arrays.sample(\n",
        "      region = ee.Feature(evalPolysList.get(g)).geometry(),\n",
        "      scale = 250,\n",
        "      numPixels = N / n,\n",
        "      seed = i,\n",
        "      tileScale = 8\n",
        "    )\n",
        "    geomSample = geomSample.merge(sample)\n",
        "\n",
        "  desc = 'eval_patches' + '_g' + str(g)\n",
        "  task = ee.batch.Export.table.toCloudStorage(\n",
        "    collection = geomSample,\n",
        "    description = desc,\n",
        "    # for Google Cloud Export\n",
        "    bucket = BUCKET,\n",
        "    fileNamePrefix = FOLDER + '/' + desc,\n",
        "    # for Google Drive Export\n",
        "    # folder = FOLDER,\n",
        "    # fileNamePrefix = desc,\n",
        "    fileFormat = 'TFRecord',\n",
        "    selectors = BANDS + [RESPONSE]\n",
        "  )\n",
        "  task.start()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training data\n",
        "\n",
        "Load the data exported from Earth Engine into a `tf.data.Dataset`."
      ],
      "metadata": {
        "id": "maGODNK_0Lxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "  Returns:\n",
        "    A dictionary of tensors, keyed by feature name.\n",
        "  \"\"\"\n",
        "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
        "\n",
        "\n",
        "def to_tuple(inputs):\n",
        "  \"\"\"Function to convert a dictionary of tensors to a tuple of (inputs, outputs).\n",
        "  Turn the tensors returned by parse_tfrecord into a stack in HWC shape.\n",
        "  Args:\n",
        "    inputs: A dictionary of tensors, keyed by feature name.\n",
        "  Returns:\n",
        "    A tuple of (inputs, outputs).\n",
        "  \"\"\"\n",
        "  inputsList = [inputs.get(key) for key in FEATURES]\n",
        "  stacked = tf.stack(inputsList, axis=0)\n",
        "  # Convert from CHW to HWC\n",
        "  stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "  return stacked[:,:,:len(BANDS)], stacked[:,:,len(BANDS):]\n",
        "\n",
        "\n",
        "def get_dataset(pattern):\n",
        "  \"\"\"Function to read, parse and format to tuple a set of input tfrecord files.\n",
        "  Get all the files matching the pattern, parse and convert to tuple.\n",
        "  Args:\n",
        "    pattern: A file pattern to match in a Cloud Storage bucket.\n",
        "  Returns:\n",
        "    A tf.data.Dataset\n",
        "  \"\"\"\n",
        "  glob = tf.io.gfile.glob(pattern)\n",
        "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
        "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "  dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "42rjNI3h0VUh"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the helpers to read in the training dataset.  Print the first record to check."
      ],
      "metadata": {
        "id": "P0w9Oc6o1BWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import train\n",
        "def get_training_dataset():\n",
        "\t\"\"\"Get the preprocessed training dataset\n",
        "  Returns:\n",
        "    A tf.data.Dataset of training data.\n",
        "  \"\"\"\n",
        "\t# directory for Google Drive\n",
        "\t# root_dir = 'drive/My Drive/'\n",
        "\t# glob = root_dir + FOLDER + '/' + 'training_patches' + '*'\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + TRAINING_BASE + '*'\n",
        "\tdataset = get_dataset(glob)\n",
        "\t# shuffle in n iterations, random pick one element from buffer in each iteration\n",
        "\t# batch in size BATCH_SIZE\n",
        "\t# repeat when all element are comsumed\n",
        "\tdataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "training = get_training_dataset()\n",
        "#\n",
        "print(iter(training.take(1)).next())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FtJDBGn1BER",
        "outputId": "b43162a3-79dc-45b8-efb6-55ab4f7dc24c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(16, 256, 256, 2), dtype=float32, numpy=\n",
            "array([[[[4665. , 2326. ],\n",
            "         [3352. , 1249. ],\n",
            "         [3352. , 1249. ],\n",
            "         ...,\n",
            "         [4017. , 2088. ],\n",
            "         [4017. , 2088. ],\n",
            "         [4017. , 2137. ]],\n",
            "\n",
            "        [[2480. , 1080. ],\n",
            "         [2607. ,  998. ],\n",
            "         [3087. , 1322. ],\n",
            "         ...,\n",
            "         [4845. , 2149. ],\n",
            "         [5146. , 2685. ],\n",
            "         [5146. , 2685. ]],\n",
            "\n",
            "        [[2375. , 1053. ],\n",
            "         [2709. , 1040. ],\n",
            "         [2851. , 1253. ],\n",
            "         ...,\n",
            "         [4771. , 2084. ],\n",
            "         [5143. , 2375. ],\n",
            "         [5143. , 2538. ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[4502. , 2514. ],\n",
            "         [4828. , 2775. ],\n",
            "         [4828. , 2775. ],\n",
            "         ...,\n",
            "         [4050. , 2027. ],\n",
            "         [4050. , 2027. ],\n",
            "         [4050. , 2027. ]],\n",
            "\n",
            "        [[5080. , 2670. ],\n",
            "         [5080. , 2456. ],\n",
            "         [5615. , 2662. ],\n",
            "         ...,\n",
            "         [3549. , 1560. ],\n",
            "         [4124. , 1917. ],\n",
            "         [4124. , 1917. ]],\n",
            "\n",
            "        [[4894. , 2548. ],\n",
            "         [5080. , 2897. ],\n",
            "         [5700. , 2555. ],\n",
            "         ...,\n",
            "         [3541. , 1760. ],\n",
            "         [4069. , 2043. ],\n",
            "         [4529. , 2388. ]]],\n",
            "\n",
            "\n",
            "       [[[5444. , 3338. ],\n",
            "         [5958. , 3715. ],\n",
            "         [5922. , 3913. ],\n",
            "         ...,\n",
            "         [5749. , 2509. ],\n",
            "         [5114. , 2854. ],\n",
            "         [6188. , 2821. ]],\n",
            "\n",
            "        [[6486. , 3670. ],\n",
            "         [6469. , 3870. ],\n",
            "         [6122. , 3351. ],\n",
            "         ...,\n",
            "         [5310. , 2606. ],\n",
            "         [5114. , 2722. ],\n",
            "         [5226. , 2699. ]],\n",
            "\n",
            "        [[4740. , 2718. ],\n",
            "         [4740. , 2718. ],\n",
            "         [5184. , 2772. ],\n",
            "         ...,\n",
            "         [4920. , 2959. ],\n",
            "         [4920. , 2972. ],\n",
            "         [4771. , 2972. ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[4568. , 2663. ],\n",
            "         [4697. , 2659. ],\n",
            "         [4226. , 2591. ],\n",
            "         ...,\n",
            "         [2642. , 1484. ],\n",
            "         [3413. , 1890. ],\n",
            "         [4542. , 2524. ]],\n",
            "\n",
            "        [[6152. , 3412. ],\n",
            "         [5498. , 3527. ],\n",
            "         [3825. , 2358. ],\n",
            "         ...,\n",
            "         [2847. , 1433. ],\n",
            "         [3042. , 1647. ],\n",
            "         [2896. , 1483. ]],\n",
            "\n",
            "        [[6174. , 3765. ],\n",
            "         [5024. , 3064. ],\n",
            "         [4796. , 2997. ],\n",
            "         ...,\n",
            "         [4426. , 2700. ],\n",
            "         [4509. , 2726. ],\n",
            "         [3289. , 1904. ]]],\n",
            "\n",
            "\n",
            "       [[[3497. , 2351. ],\n",
            "         [3317. , 2303. ],\n",
            "         [3317. , 2132. ],\n",
            "         ...,\n",
            "         [4864. , 2135. ],\n",
            "         [4550. , 1862. ],\n",
            "         [3983. , 1363. ]],\n",
            "\n",
            "        [[3317. , 2303. ],\n",
            "         [3535. , 2045. ],\n",
            "         [3535. , 2045. ],\n",
            "         ...,\n",
            "         [4200. , 2133. ],\n",
            "         [4200. , 2133. ],\n",
            "         [3243. , 1300. ]],\n",
            "\n",
            "        [[4066. , 2138. ],\n",
            "         [3535. , 1911. ],\n",
            "         [3685. , 1975. ],\n",
            "         ...,\n",
            "         [4498. , 2603. ],\n",
            "         [4008. , 2058. ],\n",
            "         [3264. , 1373. ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[3172. , 1662. ],\n",
            "         [2768. , 1627. ],\n",
            "         [2670. , 1527. ],\n",
            "         ...,\n",
            "         [2231. , 1214. ],\n",
            "         [2231. , 1214. ],\n",
            "         [2322. , 1262. ]],\n",
            "\n",
            "        [[3743. , 1960. ],\n",
            "         [3459. , 1857. ],\n",
            "         [3556. , 1880. ],\n",
            "         ...,\n",
            "         [3348. , 2049. ],\n",
            "         [3045. , 1896. ],\n",
            "         [2254. , 1337. ]],\n",
            "\n",
            "        [[3789. , 2117. ],\n",
            "         [3249. , 1861. ],\n",
            "         [3249. , 1837. ],\n",
            "         ...,\n",
            "         [3417. , 2138. ],\n",
            "         [3168. , 2045. ],\n",
            "         [2590. , 1782. ]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[4764. , 3277. ],\n",
            "         [6557. , 4543. ],\n",
            "         [6694. , 5121. ],\n",
            "         ...,\n",
            "         [2871. , 1707. ],\n",
            "         [2871. , 1707. ],\n",
            "         [2871. , 1707. ]],\n",
            "\n",
            "        [[6301. , 4212. ],\n",
            "         [5944. , 4244. ],\n",
            "         [5944. , 4244. ],\n",
            "         ...,\n",
            "         [2989. , 1738. ],\n",
            "         [2852. , 1669. ],\n",
            "         [2904. , 1686. ]],\n",
            "\n",
            "        [[4961. , 3234. ],\n",
            "         [5183. , 3292. ],\n",
            "         [6412. , 4593. ],\n",
            "         ...,\n",
            "         [2954. , 1596. ],\n",
            "         [2953. , 1604. ],\n",
            "         [2953. , 1628. ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[4102. , 2395. ],\n",
            "         [4102. , 2395. ],\n",
            "         [4777. , 2514. ],\n",
            "         ...,\n",
            "         [6230. , 3038. ],\n",
            "         [6700. , 3331. ],\n",
            "         [7037. , 3536. ]],\n",
            "\n",
            "        [[5156. , 2791. ],\n",
            "         [5257. , 2626. ],\n",
            "         [4836. , 2485. ],\n",
            "         ...,\n",
            "         [6612. , 2982. ],\n",
            "         [6612. , 2982. ],\n",
            "         [6958. , 3188. ]],\n",
            "\n",
            "        [[5383. , 2706. ],\n",
            "         [5257. , 2647. ],\n",
            "         [4488. , 2338. ],\n",
            "         ...,\n",
            "         [7540. , 2789. ],\n",
            "         [6643. , 2865. ],\n",
            "         [6338. , 3075. ]]],\n",
            "\n",
            "\n",
            "       [[[3630. , 1461. ],\n",
            "         [3182. , 1461. ],\n",
            "         [3090. , 1352. ],\n",
            "         ...,\n",
            "         [2227. ,  841. ],\n",
            "         [2504. ,  919. ],\n",
            "         [2970. , 1343. ]],\n",
            "\n",
            "        [[2857. , 1382. ],\n",
            "         [2857. , 1382. ],\n",
            "         [2778. , 1280. ],\n",
            "         ...,\n",
            "         [2813. , 1228. ],\n",
            "         [2813. , 1228. ],\n",
            "         [3257. , 1592. ]],\n",
            "\n",
            "        [[3958. , 2054. ],\n",
            "         [3550. , 1788. ],\n",
            "         [3550. , 1788. ],\n",
            "         ...,\n",
            "         [2670. , 1199. ],\n",
            "         [3222. , 1725. ],\n",
            "         [3222. , 1725. ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[2816. , 1406. ],\n",
            "         [2485. , 1138. ],\n",
            "         [2463. , 1255. ],\n",
            "         ...,\n",
            "         [2543. , 1202. ],\n",
            "         [2638. , 1456. ],\n",
            "         [2682. , 1540. ]],\n",
            "\n",
            "        [[2437. , 1246. ],\n",
            "         [2337. , 1217. ],\n",
            "         [2402. , 1148. ],\n",
            "         ...,\n",
            "         [2578. , 1255. ],\n",
            "         [3123. , 1642. ],\n",
            "         [2792. , 1456. ]],\n",
            "\n",
            "        [[2528. , 1280. ],\n",
            "         [2528. , 1280. ],\n",
            "         [2287. , 1280. ],\n",
            "         ...,\n",
            "         [2594. , 1281. ],\n",
            "         [2698. , 1594. ],\n",
            "         [2698. , 1594. ]]],\n",
            "\n",
            "\n",
            "       [[[2385. ,  992. ],\n",
            "         [2385. , 1333. ],\n",
            "         [2612. , 1333. ],\n",
            "         ...,\n",
            "         [2683. , 1147. ],\n",
            "         [2683. , 1147. ],\n",
            "         [3479. , 1807. ]],\n",
            "\n",
            "        [[2897. , 1448. ],\n",
            "         [3643. , 1884. ],\n",
            "         [3460. , 1715. ],\n",
            "         ...,\n",
            "         [ 438. ,  134. ],\n",
            "         [ 254.5,   41. ],\n",
            "         [ 254.5,   41. ]],\n",
            "\n",
            "        [[2676. , 1353. ],\n",
            "         [2676. , 1353. ],\n",
            "         [2570. , 1120. ],\n",
            "         ...,\n",
            "         [ -81. , -101. ],\n",
            "         [ 181. , -161. ],\n",
            "         [ 870. ,  222. ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[2526. , 1168. ],\n",
            "         [2560. , 1343. ],\n",
            "         [2560. , 1343. ],\n",
            "         ...,\n",
            "         [2386. , 1171. ],\n",
            "         [2428. , 1279. ],\n",
            "         [2428. , 1317. ]],\n",
            "\n",
            "        [[2575. , 1214. ],\n",
            "         [2947. , 1289. ],\n",
            "         [3192. , 1537. ],\n",
            "         ...,\n",
            "         [2376. , 1229. ],\n",
            "         [2376. , 1229. ],\n",
            "         [2848. , 1321. ]],\n",
            "\n",
            "        [[3192. , 1537. ],\n",
            "         [3192. , 1537. ],\n",
            "         [3192. , 1560. ],\n",
            "         ...,\n",
            "         [2650. , 1272. ],\n",
            "         [3074. , 1774. ],\n",
            "         [3074. , 1774. ]]]], dtype=float32)>, <tf.Tensor: shape=(16, 256, 256, 1), dtype=float32, numpy=\n",
            "array([[[[0.25807774],\n",
            "         [0.2636792 ],\n",
            "         [0.43923765],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.4001981 ],\n",
            "         [0.3908054 ],\n",
            "         [0.22873831],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.39466494],\n",
            "         [0.38694584],\n",
            "         [0.22668898],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         ...,\n",
            "         [0.38923424],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.        ],\n",
            "         [0.18741034],\n",
            "         [0.19581255],\n",
            "         ...,\n",
            "         [0.3853747 ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.        ],\n",
            "         [0.19441219],\n",
            "         [0.        ],\n",
            "         ...,\n",
            "         [0.36901426],\n",
            "         [0.        ],\n",
            "         [0.        ]]],\n",
            "\n",
            "\n",
            "       [[[0.26402077],\n",
            "         [0.26484048],\n",
            "         [0.26542112],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.1845413 ],\n",
            "         [0.25220302]],\n",
            "\n",
            "        [[0.44159436],\n",
            "         [0.26005876],\n",
            "         [0.26248378],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.25995627],\n",
            "         [0.25913656]],\n",
            "\n",
            "        [[0.2553453 ],\n",
            "         [0.2516907 ],\n",
            "         [0.41508982],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.41959834],\n",
            "         [0.2596489 ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.        ],\n",
            "         [0.        ],\n",
            "         [0.4243801 ],\n",
            "         ...,\n",
            "         [0.4011203 ],\n",
            "         [0.4143384 ],\n",
            "         [0.44046724]],\n",
            "\n",
            "        [[0.44354123],\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         ...,\n",
            "         [0.44460005],\n",
            "         [0.44391695],\n",
            "         [0.44289228]],\n",
            "\n",
            "        [[0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         ...,\n",
            "         [0.46967006],\n",
            "         [0.46215588],\n",
            "         [0.4632147 ]]],\n",
            "\n",
            "\n",
            "       [[[0.        ],\n",
            "         [0.        ],\n",
            "         [0.29062778],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.30545118],\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         ...,\n",
            "         [0.48688436],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.31002802],\n",
            "         [0.        ],\n",
            "         [0.30036205],\n",
            "         ...,\n",
            "         [0.475374  ],\n",
            "         [0.44904023],\n",
            "         [0.42998156]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.21323177],\n",
            "         [0.20988455],\n",
            "         [0.21121661],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.21654485],\n",
            "         [0.21521279],\n",
            "         [0.21804768],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.24585013],\n",
            "         [0.24677232],\n",
            "         [0.24861671],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]]],\n",
            "\n",
            "\n",
            "       ...,\n",
            "\n",
            "\n",
            "       [[[0.32263133],\n",
            "         [0.41286972],\n",
            "         [0.42164767],\n",
            "         ...,\n",
            "         [0.21370995],\n",
            "         [0.2159642 ],\n",
            "         [0.2184234 ]],\n",
            "\n",
            "        [[0.33653256],\n",
            "         [0.38554546],\n",
            "         [0.3912494 ],\n",
            "         ...,\n",
            "         [0.21753535],\n",
            "         [0.21586174],\n",
            "         [0.22306852]],\n",
            "\n",
            "        [[0.32222146],\n",
            "         [0.33899173],\n",
            "         [0.3814468 ],\n",
            "         ...,\n",
            "         [0.21572512],\n",
            "         [0.2245372 ],\n",
            "         [0.23283695]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.28967142],\n",
            "         [0.22535692],\n",
            "         [0.29332605],\n",
            "         ...,\n",
            "         [0.27245712],\n",
            "         [0.29151583],\n",
            "         [0.29199398]],\n",
            "\n",
            "        [[0.22426395],\n",
            "         [0.2705786 ],\n",
            "         [0.22911401],\n",
            "         ...,\n",
            "         [0.28239635],\n",
            "         [0.28622174],\n",
            "         [0.290013  ]],\n",
            "\n",
            "        [[0.24178565],\n",
            "         [0.3153904 ],\n",
            "         [0.29858598],\n",
            "         ...,\n",
            "         [0.2914475 ],\n",
            "         [0.        ],\n",
            "         [0.28191817]]],\n",
            "\n",
            "\n",
            "       [[[0.42270645],\n",
            "         [0.40528724],\n",
            "         [0.3882779 ],\n",
            "         ...,\n",
            "         [0.3876631 ],\n",
            "         [0.40098366],\n",
            "         [0.40508232]],\n",
            "\n",
            "        [[0.41140106],\n",
            "         [0.3916251 ],\n",
            "         [0.38158345],\n",
            "         ...,\n",
            "         [0.39299133],\n",
            "         [0.41215247],\n",
            "         [0.42250153]],\n",
            "\n",
            "        [[0.41898355],\n",
            "         [0.4258146 ],\n",
            "         [0.42103285],\n",
            "         ...,\n",
            "         [0.39992484],\n",
            "         [0.40774643],\n",
            "         [0.        ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.39770475],\n",
            "         [0.23246123],\n",
            "         [0.23099256],\n",
            "         ...,\n",
            "         [0.36074868],\n",
            "         [0.36867273],\n",
            "         [0.37345448]],\n",
            "\n",
            "        [[0.38294965],\n",
            "         [0.22539108],\n",
            "         [0.22785026],\n",
            "         ...,\n",
            "         [0.3713027 ],\n",
            "         [0.23252955],\n",
            "         [0.39411846]],\n",
            "\n",
            "        [[0.40419427],\n",
            "         [0.389405  ],\n",
            "         [0.3868092 ],\n",
            "         ...,\n",
            "         [0.37560627],\n",
            "         [0.37943166],\n",
            "         [0.3932304 ]]],\n",
            "\n",
            "\n",
            "       [[[0.3835986 ],\n",
            "         [0.3880388 ],\n",
            "         [0.3937086 ],\n",
            "         ...,\n",
            "         [0.39387935],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.41286972],\n",
            "         [0.4157388 ],\n",
            "         [0.40439922],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        [[0.39220574],\n",
            "         [0.38206163],\n",
            "         [0.3816176 ],\n",
            "         ...,\n",
            "         [0.        ],\n",
            "         [0.        ],\n",
            "         [0.        ]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.3866726 ],\n",
            "         [0.38182253],\n",
            "         [0.38516974],\n",
            "         ...,\n",
            "         [0.36597446],\n",
            "         [0.36522302],\n",
            "         [0.36874104]],\n",
            "\n",
            "        [[0.2573605 ],\n",
            "         [0.26320103],\n",
            "         [0.26975885],\n",
            "         ...,\n",
            "         [0.3652572 ],\n",
            "         [0.3694583 ],\n",
            "         [0.37727988]],\n",
            "\n",
            "        [[0.4321675 ],\n",
            "         [0.25783864],\n",
            "         [0.26060525],\n",
            "         ...,\n",
            "         [0.3758795 ],\n",
            "         [0.3972949 ],\n",
            "         [0.4152606 ]]]], dtype=float32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation data\n",
        "\n",
        "Now do the same thing to get an evaluation dataset.  Note that unlike the training dataset, the evaluation dataset has a batch size of 1, is not repeated and is not shuffled."
      ],
      "metadata": {
        "id": "beFseGNEWUpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_dataset():\n",
        "\t\"\"\"Get the preprocessed evaluation dataset\n",
        "  Returns:\n",
        "    A tf.data.Dataset of evaluation data.\n",
        "  \"\"\"\n",
        "\t# root_dir = 'drive/My Drive/'\n",
        "\t# glob = root_dir + FOLDER + '/' + 'eval_patches' + '*'\n",
        "\tglob = 'gs://' + BUCKET + '/' + FOLDER + '/' + EVAL_BASE + '*'\n",
        "\tdataset = get_dataset(glob)\n",
        "\tdataset = dataset.batch(1).repeat()\n",
        "\treturn dataset\n",
        "\n",
        "evaluation = get_eval_dataset()\n",
        "evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbSPM_a8WX6Z",
        "outputId": "2b309349-7408-414d-a65e-a5638ff3284a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_RepeatDataset element_spec=(TensorSpec(shape=(None, 256, 256, 2), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "Keras implementation of the U-Net model.  The U-Net model takes 256x256 pixel patches as input and outputs per-pixel class probability, label or a continuous output.  We can implement the model essentially unmodified, but will use mean squared error loss on the sigmoidal output since we are treating this as a regression problem, rather than a classification problem."
      ],
      "metadata": {
        "id": "s7Mtrx_YXE28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras import metrics\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "\n",
        "# TODO: test other activation functions\n",
        "\n",
        "def conv_block(input_tensor, num_filters):\n",
        "\tencoder = Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
        "\tencoder = BatchNormalization()(encoder)\n",
        "\tencoder = Activation('relu')(encoder)\n",
        "\tencoder = Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
        "\tencoder = BatchNormalization()(encoder)\n",
        "\tencoder = Activation('relu')(encoder)\n",
        "\treturn encoder\n",
        "\n",
        "def encoder_block(input_tensor, num_filters):\n",
        "\tencoder = conv_block(input_tensor, num_filters)\n",
        "\tencoder_pool = MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
        "\treturn encoder_pool, encoder\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "\tdecoder = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "\tdecoder = concatenate([concat_tensor, decoder], axis=-1)\n",
        "\tdecoder = BatchNormalization()(decoder)\n",
        "\tdecoder = Activation('relu')(decoder)\n",
        "\tdecoder = Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = BatchNormalization()(decoder)\n",
        "\tdecoder = Activation('relu')(decoder)\n",
        "\tdecoder = Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
        "\tdecoder = BatchNormalization()(decoder)\n",
        "\tdecoder = Activation('relu')(decoder)\n",
        "\treturn decoder\n",
        "\n",
        "def get_model():\n",
        "\tinputs = Input(shape=[None, None, len(BANDS)]) # 256\n",
        "\tencoder0_pool, encoder0 = encoder_block(inputs, 32) # 128\n",
        "\tencoder1_pool, encoder1 = encoder_block(encoder0_pool, 64) # 64\n",
        "\tencoder2_pool, encoder2 = encoder_block(encoder1_pool, 128) # 32\n",
        "\tencoder3_pool, encoder3 = encoder_block(encoder2_pool, 256) # 16\n",
        "\tencoder4_pool, encoder4 = encoder_block(encoder3_pool, 512) # 8\n",
        "\tcenter = conv_block(encoder4_pool, 1024) # center\n",
        "\tdecoder4 = decoder_block(center, encoder4, 512) # 16\n",
        "\tdecoder3 = decoder_block(decoder4, encoder3, 256) # 32\n",
        "\tdecoder2 = decoder_block(decoder3, encoder2, 128) # 64\n",
        "\tdecoder1 = decoder_block(decoder2, encoder1, 64) # 128\n",
        "\tdecoder0 = decoder_block(decoder1, encoder0, 32) # 256\n",
        "\toutputs = Conv2D(1, (1, 1), activation='sigmoid')(decoder0)\n",
        "\n",
        "\tmodel = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "\tmodel.compile(\n",
        "\t\toptimizer=optimizers.get(OPTIMIZER),\n",
        "\t\tloss=losses.get(LOSS),\n",
        "\t\tmetrics=[metrics.get(metric) for metric in METRICS])\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "NJr-VUE7XF08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "\n",
        "Here we're going to train for 10 epochs.  For better accuracy, optimize this parameter, for example through [hyperparamter tuning](https://cloud.google.com/ml-engine/docs/tensorflow/using-hyperparameter-tuning)."
      ],
      "metadata": {
        "id": "YCqxtyDoXtQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = get_model()\n",
        "\n",
        "m.fit(\n",
        "    x=training,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=int(TRAIN_SIZE / BATCH_SIZE),\n",
        "    validation_data=evaluation,\n",
        "    validation_steps=EVAL_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36UBzMYMXuGp",
        "outputId": "f3c74fc1-4318-442b-99e1-8f8cff2fe883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 596s 561ms/step - loss: 0.0224 - root_mean_squared_error: 0.1497 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0841\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 555s 555ms/step - loss: 0.0050 - root_mean_squared_error: 0.0708 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 529s 529ms/step - loss: 0.0043 - root_mean_squared_error: 0.0659 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0685\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 555s 555ms/step - loss: 0.0043 - root_mean_squared_error: 0.0656 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0626\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 524s 524ms/step - loss: 0.0040 - root_mean_squared_error: 0.0631 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0665\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 552s 552ms/step - loss: 0.0039 - root_mean_squared_error: 0.0626 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0631\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 550s 550ms/step - loss: 0.0040 - root_mean_squared_error: 0.0630 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0586\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 550s 550ms/step - loss: 0.0037 - root_mean_squared_error: 0.0606 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 550s 550ms/step - loss: 0.0038 - root_mean_squared_error: 0.0613 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0599\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 521s 521ms/step - loss: 0.0038 - root_mean_squared_error: 0.0616 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0562\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b96363e59c0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the model's architecture\n",
        "m.summary()\n",
        "\n",
        "# Save the weights\n",
        "m.save_weights('drive/My Drive/carbon_mapping/my_checkpoint')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odheK3XKblhh",
        "outputId": "54d9c32a-02a0-4217-802f-00e4a2112fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None, None,  0           []                               \n",
            "                                 2)]                                                              \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, None, None,   608         ['input_1[0][0]']                \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, None, None,   128        ['conv2d[0][0]']                 \n",
            " alization)                     32)                                                               \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, None, None,   0           ['batch_normalization[0][0]']    \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, None, None,   9248        ['activation[0][0]']             \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, None, None,   128        ['conv2d_1[0][0]']               \n",
            " rmalization)                   32)                                                               \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, None, None,   0           ['batch_normalization_1[0][0]']  \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, None, None,   0           ['activation_1[0][0]']           \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, None, None,   18496       ['max_pooling2d[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, None, None,   256        ['conv2d_2[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, None, None,   0           ['batch_normalization_2[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, None, None,   36928       ['activation_2[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, None, None,   256        ['conv2d_3[0][0]']               \n",
            " rmalization)                   64)                                                               \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, None, None,   0           ['batch_normalization_3[0][0]']  \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, None, None,   0          ['activation_3[0][0]']           \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, None, None,   73856       ['max_pooling2d_1[0][0]']        \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, None, None,   512        ['conv2d_4[0][0]']               \n",
            " rmalization)                   128)                                                              \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, None, None,   0           ['batch_normalization_4[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, None, None,   147584      ['activation_4[0][0]']           \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, None, None,   512        ['conv2d_5[0][0]']               \n",
            " rmalization)                   128)                                                              \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, None, None,   0           ['batch_normalization_5[0][0]']  \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, None, None,   0          ['activation_5[0][0]']           \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, None, None,   295168      ['max_pooling2d_2[0][0]']        \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, None, None,   1024       ['conv2d_6[0][0]']               \n",
            " rmalization)                   256)                                                              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, None, None,   0           ['batch_normalization_6[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, None, None,   590080      ['activation_6[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, None, None,   1024       ['conv2d_7[0][0]']               \n",
            " rmalization)                   256)                                                              \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, None, None,   0           ['batch_normalization_7[0][0]']  \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, None, None,   0          ['activation_7[0][0]']           \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, None, None,   1180160     ['max_pooling2d_3[0][0]']        \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, None, None,   2048       ['conv2d_8[0][0]']               \n",
            " rmalization)                   512)                                                              \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, None, None,   0           ['batch_normalization_8[0][0]']  \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, None, None,   2359808     ['activation_8[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, None, None,   2048       ['conv2d_9[0][0]']               \n",
            " rmalization)                   512)                                                              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, None, None,   0           ['batch_normalization_9[0][0]']  \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPooling2D)  (None, None, None,   0          ['activation_9[0][0]']           \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, None, None,   4719616     ['max_pooling2d_4[0][0]']        \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, None, None,   4096       ['conv2d_10[0][0]']              \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, None, None,   0           ['batch_normalization_10[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, None, None,   9438208     ['activation_10[0][0]']          \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, None, None,   4096       ['conv2d_11[0][0]']              \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, None, None,   0           ['batch_normalization_11[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, None, None,   2097664    ['activation_11[0][0]']          \n",
            " ose)                           512)                                                              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, None, None,   0           ['activation_9[0][0]',           \n",
            "                                1024)                             'conv2d_transpose[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, None, None,   4096       ['concatenate[0][0]']            \n",
            " ormalization)                  1024)                                                             \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, None, None,   0           ['batch_normalization_12[0][0]'] \n",
            "                                1024)                                                             \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, None, None,   4719104     ['activation_12[0][0]']          \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, None, None,   2048       ['conv2d_12[0][0]']              \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, None, None,   0           ['batch_normalization_13[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, None, None,   2359808     ['activation_13[0][0]']          \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, None, None,   2048       ['conv2d_13[0][0]']              \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, None, None,   0           ['batch_normalization_14[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, None, None,   524544     ['activation_14[0][0]']          \n",
            " spose)                         256)                                                              \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, None, None,   0           ['activation_7[0][0]',           \n",
            "                                512)                              'conv2d_transpose_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, None, None,   2048       ['concatenate_1[0][0]']          \n",
            " ormalization)                  512)                                                              \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, None, None,   0           ['batch_normalization_15[0][0]'] \n",
            "                                512)                                                              \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, None, None,   1179904     ['activation_15[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, None, None,   1024       ['conv2d_14[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, None, None,   0           ['batch_normalization_16[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, None, None,   590080      ['activation_16[0][0]']          \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, None, None,   1024       ['conv2d_15[0][0]']              \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, None, None,   0           ['batch_normalization_17[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, None, None,   131200     ['activation_17[0][0]']          \n",
            " spose)                         128)                                                              \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, None, None,   0           ['activation_5[0][0]',           \n",
            "                                256)                              'conv2d_transpose_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, None, None,   1024       ['concatenate_2[0][0]']          \n",
            " ormalization)                  256)                                                              \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, None, None,   0           ['batch_normalization_18[0][0]'] \n",
            "                                256)                                                              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, None, None,   295040      ['activation_18[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, None, None,   512        ['conv2d_16[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, None, None,   0           ['batch_normalization_19[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, None, None,   147584      ['activation_19[0][0]']          \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, None, None,   512        ['conv2d_17[0][0]']              \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, None, None,   0           ['batch_normalization_20[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, None, None,   32832      ['activation_20[0][0]']          \n",
            " spose)                         64)                                                               \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, None, None,   0           ['activation_3[0][0]',           \n",
            "                                128)                              'conv2d_transpose_3[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, None, None,   512        ['concatenate_3[0][0]']          \n",
            " ormalization)                  128)                                                              \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, None, None,   0           ['batch_normalization_21[0][0]'] \n",
            "                                128)                                                              \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, None, None,   73792       ['activation_21[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, None, None,   256        ['conv2d_18[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, None, None,   0           ['batch_normalization_22[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, None, None,   36928       ['activation_22[0][0]']          \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, None, None,   256        ['conv2d_19[0][0]']              \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, None, None,   0           ['batch_normalization_23[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_transpose_4 (Conv2DTran  (None, None, None,   8224       ['activation_23[0][0]']          \n",
            " spose)                         32)                                                               \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate)    (None, None, None,   0           ['activation_1[0][0]',           \n",
            "                                64)                               'conv2d_transpose_4[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, None, None,   256        ['concatenate_4[0][0]']          \n",
            " ormalization)                  64)                                                               \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, None, None,   0           ['batch_normalization_24[0][0]'] \n",
            "                                64)                                                               \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, None, None,   18464       ['activation_24[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, None, None,   128        ['conv2d_20[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, None, None,   0           ['batch_normalization_25[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, None, None,   9248        ['activation_25[0][0]']          \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, None, None,   128        ['conv2d_21[0][0]']              \n",
            " ormalization)                  32)                                                               \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, None, None,   0           ['batch_normalization_26[0][0]'] \n",
            "                                32)                                                               \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, None, None,   33          ['activation_26[0][0]']          \n",
            "                                1)                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,126,209\n",
            "Trainable params: 31,110,209\n",
            "Non-trainable params: 16,000\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Restore the weights\n",
        "m.load_weights('drive/My Drive/carbon_mapping/my_checkpoint')\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = m.evaluate(x=evaluation, verbose=2, steps=1000)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlZiqia4dSv4",
        "outputId": "4e9cf70e-35c1-45c5-c8b9-6efbc1f294a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/1000 - 14s - loss: 0.0051 - root_mean_squared_error: 0.0714 - 14s/epoch - 14ms/step\n",
            "Restored model, accuracy:  7.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction\n",
        "\n",
        "The prediction pipeline is:\n",
        "\n",
        "1.  Export imagery on which to do predictions from Earth Engine in TFRecord format to a Cloud Storage bucket.\n",
        "2.  Use the trained model to make the predictions.\n",
        "3.  Write the predictions to a TFRecord file in a Cloud Storage.\n",
        "4.  Upload the predictions TFRecord file to Earth Engine.\n"
      ],
      "metadata": {
        "id": "Z7NnZU9KXPAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def doExport(out_image_base, kernel_buffer, region):\n",
        "  \"\"\"Run the image export task.  Block until complete.\n",
        "  \"\"\"\n",
        "  task = ee.batch.Export.image.toDrive(\n",
        "    image = image.select(BANDS),\n",
        "    description = out_image_base,\n",
        "    folder = FOLDER,\n",
        "    fileNamePrefix = out_image_base,\n",
        "    region = region.getInfo()['coordinates'],\n",
        "    scale = 30,\n",
        "    fileFormat = 'TFRecord',\n",
        "    maxPixels = 1e10,\n",
        "    formatOptions = {\n",
        "      'patchDimensions': KERNEL_SHAPE,\n",
        "      'kernelSize': kernel_buffer,\n",
        "      'compressed': True,\n",
        "      'maxFileSize': 104857600\n",
        "    }\n",
        "  )\n",
        "  task.start()\n",
        "\n",
        "  # Block until the task completes.\n",
        "  print('Running image export to Google Drive...')\n",
        "  import time\n",
        "  while task.active():\n",
        "    time.sleep(30)\n",
        "\n",
        "  # Error condition\n",
        "  if task.status()['state'] != 'COMPLETED':\n",
        "    print('Error with image export.')\n",
        "  else:\n",
        "    print('Image export completed.')"
      ],
      "metadata": {
        "id": "pzCXrKiSXkgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def doPrediction(out_image_base, user_folder, kernel_buffer, region):\n",
        "  \"\"\"Perform inference on exported imagery, upload to Earth Engine.\n",
        "  \"\"\"\n",
        "\n",
        "  print('Looking for TFRecord files...')\n",
        "\n",
        "  # Get a list of all the files in the output bucket.\n",
        "  filesList = !gsutil ls 'drive/My Drive/'{FOLDER}\n",
        "\n",
        "  # Get only the files generated by the image export.\n",
        "  exportFilesList = [s for s in filesList if out_image_base in s]\n",
        "\n",
        "  # Get the list of image files and the JSON mixer file.\n",
        "  imageFilesList = []\n",
        "  jsonFile = None\n",
        "  for f in exportFilesList:\n",
        "    if f.endswith('.tfrecord.gz'):\n",
        "      imageFilesList.append(f)\n",
        "    elif f.endswith('.json'):\n",
        "      jsonFile = f\n",
        "\n",
        "  # Make sure the files are in the right order.\n",
        "  imageFilesList.sort()\n",
        "\n",
        "  from pprint import pprint\n",
        "  pprint(imageFilesList)\n",
        "  print(jsonFile)\n",
        "\n",
        "  import json\n",
        "  # Load the contents of the mixer file to a JSON object.\n",
        "  jsonText = !gsutil cat {jsonFile}\n",
        "  # Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "  mixer = json.loads(jsonText.nlstr)\n",
        "  pprint(mixer)\n",
        "  patches = mixer['totalPatches']\n",
        "\n",
        "  # Get set up for prediction.\n",
        "  x_buffer = int(kernel_buffer[0] / 2)\n",
        "  y_buffer = int(kernel_buffer[1] / 2)\n",
        "\n",
        "  buffered_shape = [\n",
        "      KERNEL_SHAPE[0] + kernel_buffer[0],\n",
        "      KERNEL_SHAPE[1] + kernel_buffer[1]]\n",
        "\n",
        "  imageColumns = [\n",
        "    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32)\n",
        "      for k in BANDS\n",
        "  ]\n",
        "\n",
        "  imageFeaturesDict = dict(zip(BANDS, imageColumns))\n",
        "\n",
        "  def parse_image(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, imageFeaturesDict)\n",
        "\n",
        "  def toTupleImage(inputs):\n",
        "    inputsList = [inputs.get(key) for key in BANDS]\n",
        "    stacked = tf.stack(inputsList, axis=0)\n",
        "    stacked = tf.transpose(stacked, [1, 2, 0])\n",
        "    return stacked\n",
        "\n",
        "   # Create a dataset from the TFRecord file(s) in Google Drive.\n",
        "  imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP')\n",
        "  imageDataset = imageDataset.map(parse_image, num_parallel_calls=5)\n",
        "  imageDataset = imageDataset.map(toTupleImage).batch(1)\n",
        "\n",
        "  # Perform inference.\n",
        "  print('Running predictions...')\n",
        "  predictions = m.predict(imageDataset, steps=patches, verbose=1)\n",
        "  # print(predictions[0])\n",
        "\n",
        "  print('Writing predictions...')\n",
        "  out_image_file = 'drive/My Drive/' + FOLDER + '/' + out_image_base + '.TFRecord'\n",
        "  writer = tf.io.TFRecordWriter(out_image_file)\n",
        "  patches = 0\n",
        "  for predictionPatch in predictions:\n",
        "    print('Writing patch ' + str(patches) + '...')\n",
        "    predictionPatch = predictionPatch[\n",
        "        x_buffer:x_buffer+KERNEL_SIZE, y_buffer:y_buffer+KERNEL_SIZE]\n",
        "\n",
        "    # Create an example.\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'impervious': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=predictionPatch.flatten()))\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    # Write the example.\n",
        "    writer.write(example.SerializeToString())\n",
        "    patches += 1\n",
        "\n",
        "  writer.close()\n",
        "\n",
        "  # Start the upload.\n",
        "  out_image_asset = user_folder + '/' + out_image_base\n",
        "  !earthengine upload image --asset_id={out_image_asset} {out_image_file} {jsonFile}"
      ],
      "metadata": {
        "id": "Yf9hdBLeYTYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now there's all the code needed to run the prediction pipeline, all that remains is to specify the output region in which to do the prediction, the names of the output files, where to put them, and the shape of the outputs.  In terms of the shape, the model is trained on 256x256 patches, but can work (in theory) on any patch that's big enough with even dimensions ([reference](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf)).  Because of tile boundary artifacts, give the model slightly larger patches for prediction, then clip out the middle 256x256 patch.  This is controlled with a kernel buffer, half the size of which will extend beyond the kernel buffer.  For example, specifying a 128x128 kernel will append 64 pixels on each side of the patch, to ensure that the pixels in the output are taken from inputs completely covered by the kernel."
      ],
      "metadata": {
        "id": "ImGAjvlBZ8Q0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Output assets folder: YOUR FOLDER\n",
        "user_folder = 'users/username' # INSERT YOUR FOLDER HERE.\n",
        "\n",
        "# Base file name to use for TFRecord files and assets.\n",
        "bj_image_base = 'FCNN_demo_beijing_384_'\n",
        "# Half this will extend on the sides of each patch.\n",
        "bj_kernel_buffer = [128, 128]\n",
        "# Beijing\n",
        "bj_region = ee.Geometry.Polygon(\n",
        "        [[[115.9662455210937, 40.121362012835235],\n",
        "          [115.9662455210937, 39.64293313749715],\n",
        "          [117.01818643906245, 39.64293313749715],\n",
        "          [117.01818643906245, 40.121362012835235]]], None, False)"
      ],
      "metadata": {
        "id": "DH2WryDZZ84p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the export.\n",
        "doExport(bj_image_base, bj_kernel_buffer, bj_region)"
      ],
      "metadata": {
        "id": "At-jt4h0aNCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the prediction.\n",
        "doPrediction(bj_image_base, user_folder, bj_kernel_buffer, bj_region)"
      ],
      "metadata": {
        "id": "M6_b6UqGaNq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the output\n",
        "\n",
        "One the data has been exported, the model has made predictions and the predictions have been written to a file, and the image imported to Earth Engine, it's possible to display the resultant Earth Engine asset.  Here, display the impervious area predictions over Beijing, China."
      ],
      "metadata": {
        "id": "NttHsWDVaPu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_image = ee.Image(user_folder + '/' + bj_image_base)\n",
        "mapid = out_image.getMapId({'min': 0, 'max': 1})\n",
        "map = folium.Map(location=[39.898, 116.5097])\n",
        "folium.TileLayer(\n",
        "    tiles=mapid['tile_fetcher'].url_format,\n",
        "    attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "    overlay=True,\n",
        "    name='predicted impervious',\n",
        "  ).add_to(map)\n",
        "map.add_child(folium.LayerControl())\n",
        "map"
      ],
      "metadata": {
        "id": "4qhDgNuFaSK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E-qP8IZlDgd"
      },
      "source": [
        "## Image Math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_T1aSPddwwV"
      },
      "source": [
        "Here we will calculate the aspect of our DEM. The aspect is the orientation of the slope, measured clockwise in degrees from 0 to 360, where 0 is north-facing, 90 is east-facing, 180 is south-facing, and 270 is west-facing.\n",
        "\n",
        "For fun, and to demonstrate chaining methods together, we will also compute the sin of the aspect. The sin of the aspect (when using radians) represents the \"eastness\", with +1 being directly east and -1 being directly west."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvD6GgLbwC2O"
      },
      "outputs": [],
      "source": [
        "# Get the aspect (in degrees).\n",
        "aspect = ee.Terrain.aspect(dem)\n",
        "\n",
        "# Convert to radians, compute the sin of the aspect.\n",
        "sinImage = aspect.divide(180).multiply(math.pi).sin()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823IpGNP8J99"
      },
      "source": [
        "### Display maps side-by-side 🐍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmZO4txRPlyj"
      },
      "source": [
        "We can also display multiple maps in a cell output. Here we will display the DEM on the left and the sin of ths aspect of the DEM on the right. Here is how to (roughly) interpret the colors:\n",
        "\n",
        "| West  | North/South | East |\n",
        "| ----- | ----------- | ---- |\n",
        "| green | white       | blue |\n",
        "\n",
        "We picked Mount Shasta because of it's unique east/west facing mountain faces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDZln_ws8Nvo"
      },
      "outputs": [],
      "source": [
        "map_params_mount_shasta = {\n",
        "    'center': (41.40902, -122.19492),\n",
        "    'zoom':10\n",
        "}\n",
        "map2b = Map(**map_params_mount_shasta)\n",
        "map2b.addLayer(dem, {'min': 0, 'max': 4000}, 'elevation [meters]')\n",
        "map2c = Map(**map_params_mount_shasta)\n",
        "map2c.addLayer(\n",
        "    sinImage,\n",
        "    {'min': -1, 'max': 1,\n",
        "     'palette':['green', 'white', 'blue']},\n",
        "    'sine of aspect'\n",
        ")\n",
        "widgets.HBox([map2b, map2c])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VefKqIt5QTBW"
      },
      "source": [
        "The map objects have properties that can be queried (or set) from Python code. For example, the following code prints out the center coordinates (lon, lat) of the map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45XfgGi12lFd"
      },
      "outputs": [],
      "source": [
        "map2b.center"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjxHJ3TLrUHL"
      },
      "source": [
        "The properties of maps can be linked together, in order to sychronise the behavior. Run the following cell, then zoom and/or pan one of the maps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_rCBh4XrQ3D"
      },
      "outputs": [],
      "source": [
        "def syncronize_maps(map_1, map_2):\n",
        "  map_center_link = widgets.link((map_1, 'center'), (map_2, 'center'))\n",
        "  map_zoom_link = widgets.link((map_1, 'zoom'), (map_2, 'zoom'))\n",
        "\n",
        "syncronize_maps(map2b, map2c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzeA0FDxvmTI"
      },
      "source": [
        "## Image statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDUSCTSYfkUO"
      },
      "source": [
        "We will explore image statistics by:\n",
        "\n",
        "1.   creating a map\n",
        "2.   creating a custom geometry by adding points on the map\n",
        "3.   calculating the stats of that custom geometry by calling `reduceRegion` on it.\n",
        "\n",
        "We will ultimately answer the question, \"what is the mean elevation?\" in the custom geometry that we defined.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhkfpFrDy6u4"
      },
      "source": [
        "### Draw Control: Create a Custom Geometry on a Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6-6no62vUJ8"
      },
      "source": [
        "In this section, we will create a custom geometry on the map using `ipyleflet.DrawControl` tool. If a geometry wasn't created using the tool, a default geometry is set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HUYOkJ4ltIo"
      },
      "outputs": [],
      "source": [
        "# Use ipyleaflet to add the ability to draw a geometry on our map.\n",
        "draw_control = ipyleaflet.DrawControl(\n",
        "    rectangle={},\n",
        "    polyline={},\n",
        "    circlemarker={},\n",
        ")\n",
        "def handle_draw(target, action, geo_json):\n",
        "    with output:\n",
        "      output.clear_output()\n",
        "      pprint(geo_json)\n",
        "draw_control.on_draw(handle_draw)\n",
        "\n",
        "map2d = Map(**map_init_params)\n",
        "output = widgets.Output(layout={'border': '1px solid black', 'width':\"200\"})\n",
        "map2d.addLayer(dem, {'min': 0, 'max': 1000}, 'elevation [meters]')\n",
        "map2d.add_control(draw_control)\n",
        "widgets.VBox([map2d, output])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ppnIZb-VbYP"
      },
      "source": [
        "The last geometry drawn on the map can be queries as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6ptvBkLVGKJ"
      },
      "outputs": [],
      "source": [
        "geom_clientside = draw_control.last_draw['geometry']\n",
        "geom_clientside"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CYsF3PuVM3_"
      },
      "source": [
        "It is possible that the preceding cell was run before any geometry was drawn on the map, so lets specify a default geometry in case that happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT7wI9Ew0fcM"
      },
      "outputs": [],
      "source": [
        "# If no geometry was drawn on a map, use a default geometry.\n",
        "if not geom_clientside:\n",
        "  geom_clientside = {'type': 'Polygon',\n",
        "    'coordinates': [[[-112.89, 36.46],\n",
        "                     [-113.08, 36.18],\n",
        "                     [-112.67, 36.16],\n",
        "                     [-112.89, 36.46]]]}\n",
        "\n",
        "  geom_clientside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buTzz0Xq2_ad"
      },
      "outputs": [],
      "source": [
        "# Create an Earth Engine server-side geometry\n",
        "geom = ee.Geometry(geom_clientside)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Ge9_zEUCJ2"
      },
      "source": [
        "### Spatial reduction: Calculate Stats for Our Custom Geometry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNe_-Lqbiv9i"
      },
      "source": [
        "We will use `reduceRegion` to calculate the mean elevation (in meters) for our custom geometry (that was created in the last section)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie5mfUJbvPIO"
      },
      "outputs": [],
      "source": [
        "# Compute the mean elevation in the polygon.\n",
        "meanDict = dem.reduceRegion(\n",
        "  reducer=ee.Reducer.mean(),\n",
        "  geometry=geom,\n",
        "  scale=90,\n",
        "  bestEffort=True\n",
        ")\n",
        "\n",
        "# Get the mean from the dictionary and print it.\n",
        "mean = meanDict.get('elevation')\n",
        "print('Mean elevation', mean.getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACOIndJ7-T3a"
      },
      "source": [
        "# Image Collections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmifi7Wth_rz"
      },
      "source": [
        "In this section we are going to use image collections to find the most cloudy and least cloudy images of Mountain View according to [Landsat 8](https://www.usgs.gov/landsat-missions/landsat-8-data-users-handbook) satelite imagery from 2016."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isdav8kpygVG"
      },
      "source": [
        "Specifically, we will use the [Landsat 8 Collection 2 Top of Atmosphere (TOA)](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_TOA) image collection. (TOA images have not been atmospherically corrected.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCq5JJc6vxAb"
      },
      "outputs": [],
      "source": [
        "landsat8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GtDNZnG-arZ"
      },
      "outputs": [],
      "source": [
        "# Create a geometry that is specified by the Geo for Good venue in Mountain View.\n",
        "point = ee.Geometry.Point(-122.0648754, 37.4225866)\n",
        "\n",
        "# Define a default visualization parameters for the Landsat image.\n",
        "landsat_rgb_viz = {\n",
        "    'bands': ['B4', 'B3', 'B2'],\n",
        "    'min': 0.0,\n",
        "    'max': 0.3,\n",
        "}\n",
        "\n",
        "# Filter by our Mountain View coordinates and by the year 2016, which was\n",
        "# arbitrarily chosen.\n",
        "spatialFiltered = landsat8.filterBounds(point)\n",
        "temporalFiltered = spatialFiltered.filterDate('2016-01-01', '2016-12-31')\n",
        "\n",
        "# Sort based on the amount of cloud cover.\n",
        "least_cloudy_image = temporalFiltered.sort('CLOUD_COVER').first()\n",
        "most_cloudy_image = temporalFiltered.sort('CLOUD_COVER', opt_ascending=False).first()\n",
        "\n",
        "map_most_cloudy = Map(**map_init_params)\n",
        "map_least_cloudy = Map()\n",
        "map_most_cloudy.addLayer(most_cloudy_image, landsat_rgb_viz)\n",
        "map_least_cloudy.addLayer(least_cloudy_image, landsat_rgb_viz)\n",
        "syncronize_maps(map_most_cloudy, map_least_cloudy)\n",
        "\n",
        "widgets.VBox([\n",
        "    widgets.Label(f\"CLOUD_COVER (most) = {most_cloudy_image.getInfo()['properties']['CLOUD_COVER']}\"),\n",
        "    map_most_cloudy,\n",
        "    widgets.Label(f\"CLOUD_COVER (least) = {least_cloudy_image.getInfo()['properties']['CLOUD_COVER']}\"),\n",
        "    map_least_cloudy\n",
        "],\n",
        "layout=widgets.Layout(max_height=\"600px\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ej-r9IApJ0m"
      },
      "source": [
        "## Compositing and Mosaicking\n",
        "\n",
        "Compositing, masking and mosaicking are different technqiues that we use to process image collections.\n",
        "\n",
        "**Compositing** refers to the process of aggregating individual pixel values in a collection. The median is often used in composites to remove the effects of cloud cover (bright pixels) and shadows (dark pixels).\n",
        "\n",
        "In **mosaics**, individual images are stitched together (side by side). Often it is the images that were most recent that are stitched together. We will be using the Landsat 8 dataset. You can understand why the mosaic looks the way it does by taking a look at the [Landsat orbit](https://www.youtube.com/watch?v=yPF2jpjB3Qw).\n",
        "\n",
        "We will first calculate the composite and the mosaic for Lansat 8 data for the year 2016 (year is arbitrarily chosen) for the point centered around the Geo for Good venue in Mountain View:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XURS3z0TAmka"
      },
      "outputs": [],
      "source": [
        "# Filter by the year 2016 (arbitrarily chosen).\n",
        "temporalFiltered = landsat8.filterDate('2016-01-01', '2016-12-31')\n",
        "# Calculate the mosaic.\n",
        "mosaic = temporalFiltered.mosaic()\n",
        "# Calculate the composite by getting the median over time, for each band, in\n",
        "# each pixel.\n",
        "median = temporalFiltered.median()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPx6of6zxzMV"
      },
      "source": [
        "We will display the mosaic on the right and the composite on the left:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt96jUp_yY6n"
      },
      "outputs": [],
      "source": [
        "# Compare the mosaic and composite results.\n",
        "map4a = Map(**map_init_params)\n",
        "map4a.addLayer(mosaic, landsat_rgb_viz, 'Landsat 8 (mosaic)')\n",
        "map4b = Map(**map_init_params)\n",
        "map4b.addLayer(median, landsat_rgb_viz, 'Landsat 8 (median)')\n",
        "syncronize_maps(map4a, map4b)\n",
        "widgets.HBox([map4a, map4b])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WiWNiAA7B96"
      },
      "source": [
        "Why does the mosaic have white lines?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebgiNG5069Zz"
      },
      "outputs": [],
      "source": [
        "HTML(\n",
        "  '<iframe width=\"640\" height=\"385\" '\n",
        "  'src=\"https://www.youtube.com/embed/yPF2jpjB3Qw\" '\n",
        "  'frameborder=\"0\"></iframe>')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tWCMVsgGBhV"
      },
      "source": [
        "## Masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQkzZ9A3q2pJ"
      },
      "source": [
        "Masking pixels in an image makes those pixels transparent and excludes them from analysis. Pixels with a mask values of 0 or below will be transparent, mask values between 0 and 1 will be partially rendered, whereas mask values above 1 will be fully rendered.\n",
        "\n",
        "In this example we will use a mask to only look at land data (exclude the water data) of the [Hansen Global Forest Change](https://developers.google.com/earth-engine/datasets/catalog/UMD_hansen_global_forest_change_2021_v1_9) dataset. This dataset is used because in the `datamask` column, water has a value of 2, land has the value 1, and 'no data' has the value 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PX-DdczFQT9"
      },
      "outputs": [],
      "source": [
        "# Load or import the Hansen et al. forest change dataset.\n",
        "hansenImage = ee.Image('UMD/hansen/global_forest_change_2021_v1_9')\n",
        "\n",
        "# Select the land/water mask.\n",
        "datamask = hansenImage.select('datamask')\n",
        "\n",
        "# Create a binary mask. This means we are only selecting the land pixels (based\n",
        "# on how the datamask column is defined in the dataset).\n",
        "mask = datamask.eq(1)\n",
        "\n",
        "# Update the composite mask with the water mask.\n",
        "maskedComposite = median.updateMask(mask)\n",
        "\n",
        "map4c = Map(**map_init_params)\n",
        "map4c.addLayer(maskedComposite, landsat_rgb_viz, 'masked')\n",
        "map4c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwJdjBjENI8S"
      },
      "source": [
        "# NDVI, Mapping a Function over a Collection, Quality Mosaicking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA9Vami5z9xq"
      },
      "source": [
        "In this section we will calculate the Normalized Difference Vegetation Index (NDVI) for Landsat 8 images.\n",
        "\n",
        "The NDVI is used to determine how much green vegetation exists in an area. NDVI relies on green vegetation having a strong reflectance for Near Infrared (NIR) and a weak reflectance for red light.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE9RYKaHoijm"
      },
      "source": [
        "The formula for NDVI is as follows:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{NDVI} = \\frac{\\text{NIR}-\\text{R}}{\\text{NIR}+\\text{R}}\n",
        "\\end{align}\n",
        "\n",
        "where $\\text{NIR}$ and $\\text{R}$ are the spectral reflectance in the near-infrared and red (visible) regions, respectively (source: [wikipedia](https://en.wikipedia.org/wiki/Normalized_difference_vegetation_index)).\n",
        "\n",
        "For Landsat 8 and 9:\n",
        "\n",
        "\\begin{align}\n",
        "\\text{NDVI} = \\frac{\\text{Band5}-\\text{Band4}}{\\text{Band5}+\\text{Band4}}\n",
        "\\end{align}\n",
        "\n",
        "where $\\text{Band5}$ and $\\text{Band4}$ are the corresponding Landsat bands, respectively (source: [USGS](https://www.usgs.gov/landsat-missions/landsat-normalized-difference-vegetation-index#:~:text=In%20Landsat%204%2D7%2C%20NDVI,Band%205%20%2B%20Band%204)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXg2xAvqvifs"
      },
      "source": [
        "Below are examples of NDVI calculated for two pieces of vegetation in different states.\n",
        "\n",
        "![NDVI](https://earthobservatory.nasa.gov/ContentFeature/MeasuringVegetation/Images/ndvi_example.jpg)\n",
        "\n",
        "*Image source: [earthobservatory.nasa.gov](https://earthobservatory.nasa.gov/ContentFeature/MeasuringVegetation/Images/ndvi_example.jpg)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xh7SuTG3oWX"
      },
      "source": [
        "### Calculate NDVI on a Single Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z296JNYp3dpS"
      },
      "source": [
        "First we will calculate the NDVI on a single image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBdqGdkrKTiD"
      },
      "outputs": [],
      "source": [
        "# Define a point of interest.\n",
        "point = ee.Geometry.Point(location_lonlat)\n",
        "\n",
        "# Get the least cloudy image in 2016.\n",
        "image = ee.Image(\n",
        "  landsat8.filterBounds(point)\n",
        "          .filterDate('2016-01-01', '2016-12-31')\n",
        "          .sort('CLOUD_COVER')\n",
        "          .first()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kofuuV4wuRi-"
      },
      "source": [
        "NDVI can be calculated within Earth Engine as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvxKEaR9O06C"
      },
      "outputs": [],
      "source": [
        "nir = image.select('B5')\n",
        "red = image.select('B4')\n",
        "ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T73zk-GEuix0"
      },
      "source": [
        "Let's display a map showing the `ndvi` object. We will use simple visualization  where blue is low (negative) NDVI and green is high (positive) NDVI. Water tends to result in a negative NDVI value, while clouds have NDVI values near zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAIP7DnyNb3_"
      },
      "outputs": [],
      "source": [
        "ndvi_vis_arams = {\n",
        "    'bands': 'NDVI',\n",
        "    'min': -1,\n",
        "    'max': 1,\n",
        "    'palette': ['blue', 'white', 'green']\n",
        "}\n",
        "\n",
        "map5a = Map(**map_init_params)\n",
        "map5a.addLayer(ndvi, ndvi_vis_arams, 'NDVI image')\n",
        "map5a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiF8Kyc97Z39"
      },
      "source": [
        "Because calculating band ratios (such as NDVI) is commonly done as part of a remote sensing analysis workflow, Earth Engine images have a shortcut method to make this easier: `ee.Image.normalizedDifference()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iHbLw2nPWyr"
      },
      "outputs": [],
      "source": [
        "# Remove the NDVI layer\n",
        "map5a.remove_layer(map5a.layers[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3wOypQzOiAW"
      },
      "outputs": [],
      "source": [
        "# Redefine NDVI using ee.Image.normalizedDifference, and add it back again.\n",
        "ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI')\n",
        "map5a.addLayer(ndvi, ndvi_vis_arams, 'NDVI image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk9KTmJJ8D9p"
      },
      "source": [
        "## Applying NDVI to an Image Collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9pIcInFoDg1"
      },
      "source": [
        "In Earth Engine we can apply an algorithm that works on a single image (such as calculating NDVI) to all images in a collection. To do this, we first define a Python function that that operates on a single image. In this specfic example, the function takes an image, calculates NDVI, appends it to the image, and then returns the new image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Izzr47-DP9Ye"
      },
      "outputs": [],
      "source": [
        "def add_ndvi(image):\n",
        "  ndvi = image.normalizedDifference(['B5', 'B4']).rename('NDVI')\n",
        "  return image.addBands(ndvi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIf_2AUu8nHj"
      },
      "source": [
        "To test it out, we can apply the `add_ndvi` function to a single image. *(This is a very useful pattern for testing and debugging functions that you write)*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HmYx75C8nh6"
      },
      "outputs": [],
      "source": [
        "ndvi = add_ndvi(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K691ZDpCMOFa"
      },
      "source": [
        "We can add this NDVI image to a map/inspector panel, and then use the inspector to confirm that the NDVI band was added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF1x4w2HDh1x"
      },
      "outputs": [],
      "source": [
        "map_panel_5 = MapWithInspector(**map_init_params)\n",
        "map_panel_5.map.addLayer(ndvi, ndvi_vis_arams, 'NDVI')\n",
        "map_panel_5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZuCnQM68b8J"
      },
      "source": [
        "But it is even more useful to \"map\" (i.e. apply) the function over all the images in an image collection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9HaSYH08YxW"
      },
      "outputs": [],
      "source": [
        "with_ndvi = landsat8.map(add_ndvi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Udenzq4qNUnk"
      },
      "source": [
        "We can then mosaic the images together, and display it. Note that many images processed by the `add_ndvi` function are visible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyx8qq1YMfTk"
      },
      "outputs": [],
      "source": [
        "map5b = Map(**map_init_params)\n",
        "map5b.addLayer(with_ndvi.mosaic(), ndvi_vis_arams, 'NDVI mosaic')\n",
        "map5b.zoom = 8  # zoom out a bit from the default\n",
        "map5b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkkJXjewNEez"
      },
      "source": [
        "Note that the result is pretty noisy, because `.mosaic()` preferentialy selects the latest pixels in the collection (which often may have clouds). We will improve upon this in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsNJu3QrEzLa"
      },
      "source": [
        "## Make a greenest pixel composite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVks7JhW4Td8"
      },
      "source": [
        "In this section we will use [`qualityMosaic`](https://developers.google.com/earth-engine/apidocs/ee-imagecollection-qualitymosaic) to get less noisy NDVI data. `qualityMosaic` works by taking the maximum value composite for the band you provide. In our example, this means choosing the pixel with the largest NDVI value. The maximum is taken to avoid areas with clouds, which have very low NDVI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sadNR0nkD7-o"
      },
      "outputs": [],
      "source": [
        "greenest = with_ndvi.qualityMosaic('NDVI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsX9EkhUPfdj"
      },
      "outputs": [],
      "source": [
        "map5c = Map(**map_init_params)\n",
        "map5c.addLayer(greenest, landsat_rgb_viz, 'greenest pixel mosaic')\n",
        "map5c.zoom = 8  # zoom out a bit from the default\n",
        "map5c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cthndqoQVjf"
      },
      "source": [
        "# Exporting Charts and Images\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqIu33YGQbwn"
      },
      "source": [
        "## Charting 🐍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hC35DwK8DeO"
      },
      "source": [
        "Python has many plotting options, for example: matplotlib, bokeh, altair, plotly, etc. You can refer to [The Python Visualization Landscape](https://www.youtube.com/watch?v=FytuB8nFHPQ) talk from PyCon 2017 for more information on the plotting libraries that Python offers.\n",
        "\n",
        "The goal of this section is to create a timeseries plot using Altair to showcase one Python plotting library.\n",
        "\n",
        "We will create a timeseries plot of NDVI for the Geo for Good venue in Mountain View."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FywVeUsNWLrs"
      },
      "outputs": [],
      "source": [
        "stat_region = ee.Geometry.Point(location_lonlat)\n",
        "stat_region.getInfo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoOJzSex-Fxw"
      },
      "source": [
        "Filter the NDVI image collection to only get images that occur in the Geo for Good venue in Mountain View:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIn6qKSXUS3h"
      },
      "outputs": [],
      "source": [
        "filtered = with_ndvi.filterBounds(stat_region)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6Ed3leS-f91"
      },
      "source": [
        "Create a function that takes the image and creates an `ee.Feature` with the mean and the image timestamp (to help enable timeseries plotting):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV8HbweuRLnB"
      },
      "outputs": [],
      "source": [
        "def reduce_region_function(img):\n",
        "  \"\"\"Return a feature containing the mean value of a region and a timestamp.\"\"\"\n",
        "\n",
        "  stat = img.reduceRegion(\n",
        "      reducer=ee.Reducer.mean(),\n",
        "      geometry=stat_region,\n",
        "      scale=30\n",
        "  )\n",
        "  return ee.Feature(stat_region, stat).set({'millis': img.date().millis()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM-oZ_45_BF2"
      },
      "source": [
        "The next two code blocks are helper functions that are used to get the feature properties into a dictionary and then the dictionary values into a pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi7geadA7a9M"
      },
      "outputs": [],
      "source": [
        "# Define a function to transfer feature properties to a dictionary.\n",
        "def fc_to_dict(fc):\n",
        "  prop_names = fc.first().propertyNames()\n",
        "  prop_lists = fc.reduceColumns(\n",
        "      reducer=ee.Reducer.toList().repeat(prop_names.size()),\n",
        "      selectors=prop_names).get('list')\n",
        "\n",
        "  return ee.Dictionary.fromLists(prop_names, prop_lists)\n",
        "\n",
        "def fc_to_dataframe(fc):\n",
        "  \"\"\"Converts a feature collection to a Pandas dataframe.\"\"\"\n",
        "  return pd.DataFrame(fc_to_dict(fc).getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdxgob7A_M4b"
      },
      "source": [
        ":Here we apply the helper functions defined above to create a Pandas dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ1k9-qHQnM3"
      },
      "outputs": [],
      "source": [
        "stat_fc = (\n",
        "  ee.FeatureCollection(\n",
        "    filtered.map(reduce_region_function)\n",
        "  ).filter(\n",
        "    ee.Filter.notNull(filtered.first().bandNames())\n",
        "  )\n",
        ")\n",
        "df = fc_to_dataframe(stat_fc)\n",
        "df['timestamp'] = pd.to_datetime(df['millis'], unit='ms')\n",
        "#df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvx7blMr_Um2"
      },
      "source": [
        "Next we narrow our scope of the feature collection to only focus on the bands that matter for NDVI, the `B5` (near-infrared), `B4` (red) and `NDVI` bands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBlOGpBw3fcb"
      },
      "outputs": [],
      "source": [
        "keys = ['B5', 'B4', 'NDVI']\n",
        "source = pd.melt(\n",
        "    df[['B5', 'B4', 'NDVI', 'timestamp']],\n",
        "    id_vars='timestamp',\n",
        "    value_vars=keys,\n",
        "    var_name='band'\n",
        ")\n",
        "source.head()  # display the first few values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UPngbuW_mUU"
      },
      "source": [
        "Here we use the dataframe to plot the timeseries for B5, B4, and NDVI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeKYcEQl3qh9"
      },
      "outputs": [],
      "source": [
        "alt.Chart(source).mark_line().encode(\n",
        "    x='timestamp:T',\n",
        "    y='value',\n",
        "    color=alt.Color(\n",
        "        'band',\n",
        "        scale=alt.Scale(\n",
        "            domain=['B4', 'B5', 'NDVI'],\n",
        "            range=['red', 'purple', 'green']\n",
        "        )\n",
        "    ),\n",
        "    tooltip=['band', 'value', 'timestamp:T']\n",
        ").interactive(bind_y=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkgclKMOit8S"
      },
      "source": [
        "## Exporting Images 🐍"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVvqIRQHSb4b"
      },
      "source": [
        "This section will demonstrat how to export an image, using the Python client library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbkwB9zySiQ4"
      },
      "source": [
        "To start, create a 3-band, 8-bit, color-IR composite that we will export."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGq1erzliJdB"
      },
      "outputs": [],
      "source": [
        "visualization = greenest.visualize(**landsat_rgb_viz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZt-ufJtHrug"
      },
      "source": [
        "We can preview the visualization by adding it to an interative map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqRbjN3rlMtj"
      },
      "outputs": [],
      "source": [
        "map_init_params_eastern_sierra = {\n",
        "    'center': (37.05, -118.40),\n",
        "    'zoom':8\n",
        "}\n",
        "map6a = Map(**map_init_params_eastern_sierra)\n",
        "map6a.addLayer(visualization, {}, 'visualization test')\n",
        "map6a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7e2DHhfSruB"
      },
      "source": [
        "Next we can create a *task* that can be used to export the image. Note that a task will not run until it is *started*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0vhmjTKlHii"
      },
      "outputs": [],
      "source": [
        "asset_id = 'projects/ee-ee-test-te/assets/temp/g4g22_python_export_example'\n",
        "\n",
        "task = ee.batch.Export.image.toAsset(\n",
        "      visualization,\n",
        "      description='Greenest_pixel_composite',\n",
        "      assetId=asset_id,\n",
        "      scale=30,\n",
        "      region=\"\"\"[[[-119.2, 37.9],\n",
        "                  [-119.2, 36.2],\n",
        "                  [-117.6, 36.2],\n",
        "                  [-117.6, 37.9]]]\"\"\"  # California, East Side of Sierras\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RydLfFZBTRTo"
      },
      "source": [
        "The task can take ~10 minutes to finish. For this training, we already ran the task, so the `start()` call has been commented out. However, if you have updated the analysis and want to export a new image, you can uncomment the following line and run it (after first updating the `asset_id` in the previous cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3I2UQrzTPWf"
      },
      "outputs": [],
      "source": [
        "# task.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSoo6256lzTM"
      },
      "source": [
        "You can check on the status of your task by visitng the Earth Engine task manager webpage: https://code.earthengine.google.com/tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-6kCjw__il2"
      },
      "outputs": [],
      "source": [
        "exported_asset = ee.Image(asset_id)\n",
        "\n",
        "map6b = Map(**map_init_params_eastern_sierra)\n",
        "map6b.addLayer(exported_asset, {}, 'exported asset')\n",
        "map6b"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}